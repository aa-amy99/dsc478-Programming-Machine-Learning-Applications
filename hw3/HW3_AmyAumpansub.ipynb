{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSC478 Winter 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amy Aumpansub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due Date: Feb 26th, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color=blue>Using Python 3.7 for all tasks performed<font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Amy\\\\Desktop\\\\dsc478\\\\communities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_validate\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Load and preprocess the data using Pandas or Numpy and, if necessary, preprocessing functions from scikit-learn. The provided data is already normalized (see description), so there is no need for additional normalization. Compute and display basic statistics (mean, standard deviation, min, max, etc.) for each of the variables in the data set. Separate the target attribute for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Com = pd.read_csv('communities.csv',na_values=['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state        communityname  population  householdsize  racepctblack  \\\n",
       "0      8         Lakewoodcity        0.19           0.33          0.02   \n",
       "1     53          Tukwilacity        0.00           0.16          0.12   \n",
       "2     24         Aberdeentown        0.00           0.42          0.49   \n",
       "3     34  Willingborotownship        0.04           0.77          1.00   \n",
       "4     42    Bethlehemtownship        0.01           0.55          0.02   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  \\\n",
       "0          0.90          0.12         0.17         0.34         0.47   \n",
       "1          0.74          0.45         0.07         0.26         0.59   \n",
       "2          0.56          0.17         0.04         0.39         0.47   \n",
       "3          0.08          0.12         0.10         0.51         0.50   \n",
       "4          0.95          0.09         0.05         0.38         0.38   \n",
       "\n",
       "          ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0         ...                 0.0            0.12              0.42   \n",
       "1         ...                 0.0            0.21              0.50   \n",
       "2         ...                 0.0            0.14              0.49   \n",
       "3         ...                 0.0            0.19              0.30   \n",
       "4         ...                 0.0            0.11              0.72   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.50           0.51            0.64      0.12     0.26   \n",
       "1            0.34           0.60            0.52      0.02     0.12   \n",
       "2            0.54           0.67            0.56      0.01     0.21   \n",
       "3            0.73           0.64            0.65      0.02     0.39   \n",
       "4            0.64           0.61            0.53      0.04     0.09   \n",
       "\n",
       "   PctUsePubTrans  ViolentCrimesPerPop  \n",
       "0            0.20                 0.20  \n",
       "1            0.45                 0.67  \n",
       "2            0.02                 0.43  \n",
       "3            0.28                 0.12  \n",
       "4            0.02                 0.03  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Com.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Com.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Greenvillecity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.683551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057593</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.144022</td>\n",
       "      <td>0.424218</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.215552</td>\n",
       "      <td>0.608892</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.651530</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.232854</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>0.237979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.397553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>0.181352</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.198221</td>\n",
       "      <td>0.109459</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.229055</td>\n",
       "      <td>0.232985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              state   communityname   population  householdsize  racepctblack  \\\n",
       "count   1994.000000            1994  1994.000000    1994.000000   1994.000000   \n",
       "unique          NaN            1828          NaN            NaN           NaN   \n",
       "top             NaN  Greenvillecity          NaN            NaN           NaN   \n",
       "freq            NaN               5          NaN            NaN           NaN   \n",
       "mean      28.683551             NaN     0.057593       0.463395      0.179629   \n",
       "std       16.397553             NaN     0.126906       0.163717      0.253442   \n",
       "min        1.000000             NaN     0.000000       0.000000      0.000000   \n",
       "25%       12.000000             NaN     0.010000       0.350000      0.020000   \n",
       "50%       34.000000             NaN     0.020000       0.440000      0.060000   \n",
       "75%       42.000000             NaN     0.050000       0.540000      0.230000   \n",
       "max       56.000000             NaN     1.000000       1.000000      1.000000   \n",
       "\n",
       "        racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  \\\n",
       "count    1994.000000   1994.000000  1994.000000  1994.000000  1994.000000   \n",
       "unique           NaN           NaN          NaN          NaN          NaN   \n",
       "top              NaN           NaN          NaN          NaN          NaN   \n",
       "freq             NaN           NaN          NaN          NaN          NaN   \n",
       "mean        0.753716      0.153681     0.144022     0.424218     0.493867   \n",
       "std         0.244039      0.208877     0.232492     0.155196     0.143564   \n",
       "min         0.000000      0.000000     0.000000     0.000000     0.000000   \n",
       "25%         0.630000      0.040000     0.010000     0.340000     0.410000   \n",
       "50%         0.850000      0.070000     0.040000     0.400000     0.480000   \n",
       "75%         0.940000      0.170000     0.160000     0.470000     0.540000   \n",
       "max         1.000000      1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               ...             NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "count          ...           1994.000000     1994.000000       1994.000000   \n",
       "unique         ...                   NaN             NaN               NaN   \n",
       "top            ...                   NaN             NaN               NaN   \n",
       "freq           ...                   NaN             NaN               NaN   \n",
       "mean           ...              0.022778        0.215552          0.608892   \n",
       "std            ...              0.100400        0.231134          0.204329   \n",
       "min            ...              0.000000        0.000000          0.000000   \n",
       "25%            ...              0.000000        0.060000          0.470000   \n",
       "50%            ...              0.000000        0.130000          0.630000   \n",
       "75%            ...              0.000000        0.280000          0.777500   \n",
       "max            ...              1.000000        1.000000          1.000000   \n",
       "\n",
       "        PctSameHouse85  PctSameCity85  PctSameState85     LandArea  \\\n",
       "count      1994.000000    1994.000000     1994.000000  1994.000000   \n",
       "unique             NaN            NaN             NaN          NaN   \n",
       "top                NaN            NaN             NaN          NaN   \n",
       "freq               NaN            NaN             NaN          NaN   \n",
       "mean          0.535050       0.626424        0.651530     0.065231   \n",
       "std           0.181352       0.200521        0.198221     0.109459   \n",
       "min           0.000000       0.000000        0.000000     0.000000   \n",
       "25%           0.420000       0.520000        0.560000     0.020000   \n",
       "50%           0.540000       0.670000        0.700000     0.040000   \n",
       "75%           0.660000       0.770000        0.790000     0.070000   \n",
       "max           1.000000       1.000000        1.000000     1.000000   \n",
       "\n",
       "            PopDens  PctUsePubTrans  ViolentCrimesPerPop  \n",
       "count   1994.000000     1994.000000          1994.000000  \n",
       "unique          NaN             NaN                  NaN  \n",
       "top             NaN             NaN                  NaN  \n",
       "freq            NaN             NaN                  NaN  \n",
       "mean       0.232854        0.161685             0.237979  \n",
       "std        0.203092        0.229055             0.232985  \n",
       "min        0.000000        0.000000             0.000000  \n",
       "25%        0.100000        0.020000             0.070000  \n",
       "50%        0.170000        0.070000             0.150000  \n",
       "75%        0.280000        0.190000             0.330000  \n",
       "max        1.000000        1.000000             1.000000  \n",
       "\n",
       "[11 rows x 100 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Com.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From statistics above, the attribute values are normailized, being in the range from 0 to 1. We have missing values, which we be replaced by the mean attribute in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing data\n",
    "np.sum(np.array(pd.isnull(DF_Com)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the missing value for numerics\n",
    "missing_value = pd.DataFrame(DF_Com.isnull().sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communityname</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>householdsize</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racepctblack</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctWhite</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctAsian</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctHisp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct16t24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct65up</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbUrban</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctUrban</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medIncome</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWWage</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWInvInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWSocSec</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWRetire</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medFamInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perCapInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitePerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blackPerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indianPerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AsianPerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OtherPerCap</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HispPerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumUnderPov</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedNumBR</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HousVacant</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousOccup</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentLowQ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentMedian</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentHighQ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedRent</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInShelters</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumStreet</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctBornSameState</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameCity85</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameState85</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandArea</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PopDens</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "state                  0\n",
       "communityname          0\n",
       "population             0\n",
       "householdsize          0\n",
       "racepctblack           0\n",
       "racePctWhite           0\n",
       "racePctAsian           0\n",
       "racePctHisp            0\n",
       "agePct12t21            0\n",
       "agePct12t29            0\n",
       "agePct16t24            0\n",
       "agePct65up             0\n",
       "numbUrban              0\n",
       "pctUrban               0\n",
       "medIncome              0\n",
       "pctWWage               0\n",
       "pctWFarmSelf           0\n",
       "pctWInvInc             0\n",
       "pctWSocSec             0\n",
       "pctWPubAsst            0\n",
       "pctWRetire             0\n",
       "medFamInc              0\n",
       "perCapInc              0\n",
       "whitePerCap            0\n",
       "blackPerCap            0\n",
       "indianPerCap           0\n",
       "AsianPerCap            0\n",
       "OtherPerCap            1\n",
       "HispPerCap             0\n",
       "NumUnderPov            0\n",
       "...                   ..\n",
       "MedNumBR               0\n",
       "HousVacant             0\n",
       "PctHousOccup           0\n",
       "PctHousOwnOcc          0\n",
       "PctVacantBoarded       0\n",
       "PctVacMore6Mos         0\n",
       "MedYrHousBuilt         0\n",
       "PctHousNoPhone         0\n",
       "PctWOFullPlumb         0\n",
       "OwnOccLowQuart         0\n",
       "OwnOccMedVal           0\n",
       "OwnOccHiQuart          0\n",
       "RentLowQ               0\n",
       "RentMedian             0\n",
       "RentHighQ              0\n",
       "MedRent                0\n",
       "MedRentPctHousInc      0\n",
       "MedOwnCostPctInc       0\n",
       "MedOwnCostPctIncNoMtg  0\n",
       "NumInShelters          0\n",
       "NumStreet              0\n",
       "PctForeignBorn         0\n",
       "PctBornSameState       0\n",
       "PctSameHouse85         0\n",
       "PctSameCity85          0\n",
       "PctSameState85         0\n",
       "LandArea               0\n",
       "PopDens                0\n",
       "PctUsePubTrans         0\n",
       "ViolentCrimesPerPop    0\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values of \"OtherPerCap\" with its mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28474159558454626"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filling in the missing value with Mean attribute\n",
    "meanPerCap = DF_Com.OtherPerCap.mean()\n",
    "meanPerCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [state, communityname, population, householdsize, racepctblack, racePctWhite, racePctAsian, racePctHisp, agePct12t21, agePct12t29, agePct16t24, agePct65up, numbUrban, pctUrban, medIncome, pctWWage, pctWFarmSelf, pctWInvInc, pctWSocSec, pctWPubAsst, pctWRetire, medFamInc, perCapInc, whitePerCap, blackPerCap, indianPerCap, AsianPerCap, OtherPerCap, HispPerCap, NumUnderPov, PctPopUnderPov, PctLess9thGrade, PctNotHSGrad, PctBSorMore, PctUnemployed, PctEmploy, PctEmplManu, PctEmplProfServ, MalePctDivorce, MalePctNevMarr, FemalePctDiv, TotalPctDiv, PersPerFam, PctFam2Par, PctKids2Par, PctYoungKids2Par, PctTeen2Par, PctWorkMomYoungKids, PctWorkMom, NumIlleg, PctIlleg, NumImmig, PctImmigRecent, PctImmigRec5, PctImmigRec8, PctImmigRec10, PctRecentImmig, PctRecImmig5, PctRecImmig8, PctRecImmig10, PctSpeakEnglOnly, PctNotSpeakEnglWell, PctLargHouseFam, PctLargHouseOccup, PersPerOccupHous, PersPerOwnOccHous, PersPerRentOccHous, PctPersOwnOccup, PctPersDenseHous, PctHousLess3BR, MedNumBR, HousVacant, PctHousOccup, PctHousOwnOcc, PctVacantBoarded, PctVacMore6Mos, MedYrHousBuilt, PctHousNoPhone, PctWOFullPlumb, OwnOccLowQuart, OwnOccMedVal, OwnOccHiQuart, RentLowQ, RentMedian, RentHighQ, MedRent, MedRentPctHousInc, MedOwnCostPctInc, MedOwnCostPctIncNoMtg, NumInShelters, NumStreet, PctForeignBorn, PctBornSameState, PctSameHouse85, PctSameCity85, PctSameState85, LandArea, PopDens, PctUsePubTrans, ViolentCrimesPerPop]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Com.OtherPerCap.fillna(meanPerCap, axis=0, inplace=True)\n",
    "DF_Com[DF_Com.OtherPerCap.isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Com.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for other missing data\n",
    "np.sum(np.array(pd.isnull(DF_Com)),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is now clean, the we will drop some attributes and separate target attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate attributes for x vars and y var\n",
    "Com_x = DF_Com.drop(['state','communityname','ViolentCrimesPerPop'], axis=1, inplace = False)\n",
    "Com_y = DF_Com['ViolentCrimesPerPop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.19           0.33          0.02          0.90          0.12   \n",
       "1        0.00           0.16          0.12          0.74          0.45   \n",
       "2        0.00           0.42          0.49          0.56          0.17   \n",
       "3        0.04           0.77          1.00          0.08          0.12   \n",
       "4        0.01           0.55          0.02          0.95          0.09   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "0         0.17         0.34         0.47         0.29        0.32   \n",
       "1         0.07         0.26         0.59         0.35        0.27   \n",
       "2         0.04         0.39         0.47         0.28        0.32   \n",
       "3         0.10         0.51         0.50         0.34        0.21   \n",
       "4         0.05         0.38         0.38         0.23        0.36   \n",
       "\n",
       "        ...        NumInShelters  NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0       ...                 0.04        0.0            0.12              0.42   \n",
       "1       ...                 0.00        0.0            0.21              0.50   \n",
       "2       ...                 0.00        0.0            0.14              0.49   \n",
       "3       ...                 0.00        0.0            0.19              0.30   \n",
       "4       ...                 0.00        0.0            0.11              0.72   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.50           0.51            0.64      0.12     0.26   \n",
       "1            0.34           0.60            0.52      0.02     0.12   \n",
       "2            0.54           0.67            0.56      0.01     0.21   \n",
       "3            0.73           0.64            0.65      0.02     0.39   \n",
       "4            0.64           0.61            0.53      0.04     0.09   \n",
       "\n",
       "   PctUsePubTrans  \n",
       "0            0.20  \n",
       "1            0.45  \n",
       "2            0.02  \n",
       "3            0.28  \n",
       "4            0.02  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Com_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.20\n",
       "1    0.67\n",
       "2    0.43\n",
       "3    0.12\n",
       "4    0.03\n",
       "Name: ViolentCrimesPerPop, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Com_y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Perform standard linear regression on data using the implementation for Ch. 8 of MLA. Compute the RMSE value on the full training data. Also, plot the correlation between the predicted and actual values of the target attribute. Display the obtained regression coefficients (weights). Finally, perform 10-fold cross- validation and compare the cross-validation RMSE to the training RMSE (for cross validation, you should use the KFoldmodule from sklearn.cross_validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform standard linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = np.array(Com_x)\n",
    "x_var = np.array([np.concatenate((v,[1])) for v in x_var])\n",
    "y_var = np.array(Com_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from Ch. 8 of MLA\n",
    "def standRegres(xArr, yArr):\n",
    "    xMat = np.matrix(xArr) ; yMat = np.matrix(yArr).T\n",
    "    xTx = xMat.T*xMat\n",
    "    if np.linalg.det(xTx) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "    else:\n",
    "        ws = xTx.I * (xMat.T*yMat)\n",
    "        return ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the obtained regression coefficients (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Coefficients: [[ 1.31108068e-01]\n",
      " [-3.14114977e-02]\n",
      " [ 2.09909670e-01]\n",
      " [-4.05351612e-02]\n",
      " [-1.38892919e-02]\n",
      " [ 5.89726825e-02]\n",
      " [ 1.23399025e-01]\n",
      " [-2.22621600e-01]\n",
      " [-1.47500199e-01]\n",
      " [ 5.01635477e-02]\n",
      " [-2.42413829e-01]\n",
      " [ 4.64024392e-02]\n",
      " [-1.96945615e-01]\n",
      " [-2.06117500e-01]\n",
      " [ 4.65935490e-02]\n",
      " [-1.77212915e-01]\n",
      " [ 6.30148504e-02]\n",
      " [ 1.14942190e-02]\n",
      " [-9.08951848e-02]\n",
      " [ 2.74640044e-01]\n",
      " [ 1.01752476e-01]\n",
      " [-3.31517562e-01]\n",
      " [-2.91799268e-02]\n",
      " [-3.54483393e-02]\n",
      " [ 2.26173855e-02]\n",
      " [ 4.30950137e-02]\n",
      " [ 3.44408548e-02]\n",
      " [ 1.28412458e-01]\n",
      " [-1.91293360e-01]\n",
      " [-1.00769002e-01]\n",
      " [ 6.46856092e-02]\n",
      " [ 1.06062117e-01]\n",
      " [ 2.44125988e-06]\n",
      " [ 2.34984611e-01]\n",
      " [-3.75705330e-02]\n",
      " [-7.74957660e-03]\n",
      " [ 4.66779619e-01]\n",
      " [ 2.26295907e-01]\n",
      " [ 1.74621953e-01]\n",
      " [-5.75206227e-01]\n",
      " [-1.41954207e-01]\n",
      " [ 5.68782538e-02]\n",
      " [-3.51066745e-01]\n",
      " [-3.49493414e-02]\n",
      " [ 4.63705978e-04]\n",
      " [ 5.57016681e-02]\n",
      " [-1.82238360e-01]\n",
      " [-1.54646442e-01]\n",
      " [ 1.26172899e-01]\n",
      " [-1.44320569e-01]\n",
      " [ 2.39071713e-02]\n",
      " [ 3.33390229e-02]\n",
      " [-7.42297409e-02]\n",
      " [ 3.59876412e-02]\n",
      " [-3.31691535e-02]\n",
      " [-2.18174916e-01]\n",
      " [ 4.45777391e-01]\n",
      " [-2.00030978e-01]\n",
      " [-2.67307658e-02]\n",
      " [-1.41457254e-01]\n",
      " [ 6.38133109e-02]\n",
      " [-2.10115806e-01]\n",
      " [ 6.51276465e-01]\n",
      " [-8.02774919e-02]\n",
      " [-2.53817057e-01]\n",
      " [-6.66334925e-01]\n",
      " [ 2.01002575e-01]\n",
      " [ 1.03326247e-01]\n",
      " [ 2.88599766e-02]\n",
      " [ 1.68314795e-01]\n",
      " [-4.00752791e-02]\n",
      " [ 5.53867355e-01]\n",
      " [ 4.70396419e-02]\n",
      " [-7.64314747e-02]\n",
      " [-2.89277350e-02]\n",
      " [ 1.40739015e-02]\n",
      " [-1.40629951e-02]\n",
      " [-3.46854609e-01]\n",
      " [ 2.67796471e-01]\n",
      " [ 1.19446906e-02]\n",
      " [-2.36996317e-01]\n",
      " [-2.60764386e-02]\n",
      " [-6.84041742e-02]\n",
      " [ 3.74730887e-01]\n",
      " [ 4.17402525e-02]\n",
      " [-4.45747318e-02]\n",
      " [-8.34683479e-02]\n",
      " [ 1.30736305e-01]\n",
      " [ 1.83468559e-01]\n",
      " [ 1.26046949e-01]\n",
      " [ 4.63490658e-03]\n",
      " [-2.24577196e-02]\n",
      " [ 2.88627319e-02]\n",
      " [ 1.30622513e-02]\n",
      " [ 2.76170980e-02]\n",
      " [-1.24479622e-02]\n",
      " [-3.73099899e-02]\n",
      " [ 5.88079813e-01]]\n"
     ]
    }
   ],
   "source": [
    "std_linear_reg = standRegres(x_var,y_var)\n",
    "print (\"Regression Coefficients:\" , std_linear_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on Full Training data is 0.12888961\n"
     ]
    }
   ],
   "source": [
    "#Calculate RMSE\n",
    "pred_y = x_var*std_linear_reg\n",
    "pred_y_T = pred_y.T\n",
    "error = pred_y_T - y_var\n",
    "totalError = np.dot(error,error.T)\n",
    "# Compute RMSE\n",
    "totalRMSE = np.sqrt(totalError/len(pred_y))\n",
    "print(\"The RMSE on Full Training data is %.8f\" %totalRMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE on the full training data is: 0.12888961."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the correlation between the predicted and actual values of the target attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot correlation outputs\n",
    "plt.plot( pred_y, y_var, 'ro')\n",
    "plt.plot([0,1.1,0.1],[0,1.1,0.1])\n",
    "plt.xlabel('Predicted Y Values')\n",
    "plt.ylabel('Actual Y Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform 10-fold cross- validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "kf = KFold( n_splits=n)\n",
    "xval_err = 0\n",
    "for train,test in kf.split(x_var):\n",
    "    std_linear_reg = standRegres(x_var[train],y_var[train])\n",
    "    pred_y = (x_var[test])*std_linear_reg\n",
    "    pred_y_T = pred_y.T\n",
    "    error = pred_y_T - y_var[test]\n",
    "    xval_err += np.sqrt(np.dot(error,error.T)/len(x_var[test]))\n",
    "       \n",
    "rmse_10cv =  xval_err/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE from full training data is 0.128890\n",
      "The RMSE from 10 K-folds is 0.135861\n"
     ]
    }
   ],
   "source": [
    "print(\"The RMSE from full training data is %f\" %totalRMSE)\n",
    "print(\"The RMSE from 10 K-folds is %f\" %rmse_10cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The RMSE from 10 K-folds is 0.135861 which is sightly higher than the RMSE on the full training set of 0.12889, so our test error appears to be higher than a train error, implying the possibly overfitting of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. FeatureSelection: usethescikit - learnregressionmodelfromsklearn.linear_modelwithasubset of features to perform linear regression. For feature selection, write a script or function that takes as input the training data, target variable; the model; and any other parameters you find necessary, and returns the optimal percentage of the most informative features to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = np.array(Com_x)\n",
    "x_var = np.array([np.concatenate((v,[1])) for v in x_var])\n",
    "y_var = np.array(Com_y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.11276434604143286\n",
      "6 0.10096844171088974\n",
      "11 0.1012454264655901\n",
      "16 0.10147215844032367\n",
      "21 0.09913148807800067\n",
      "26 0.0967179060082417\n",
      "31 0.09664793348053294\n",
      "36 0.09594670962182875\n",
      "41 0.09639889059415219\n",
      "46 0.09652184062942389\n",
      "51 0.09647921584126622\n",
      "56 0.09679079983772171\n",
      "61 0.0975314605409422\n",
      "66 0.09770773121088558\n",
      "71 0.09757826948814126\n",
      "76 0.09764515944381032\n",
      "81 0.09796099073513448\n",
      "86 0.09810226228581406\n",
      "91 0.09726492465875944\n",
      "96 0.09744278456218332\n",
      "\n",
      " Optimal percentile of features:36 \n",
      "\n",
      "Optimal number of features:34 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modify function from Lec 6 example of Feature / Model Selection Strategies\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_var, y_var, test_size=0.2)\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "percentiles = range(1, 100, 5)\n",
    "results = []\n",
    "for i in range(1, 100, 5):\n",
    "    fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=i)\n",
    "    X_train_fs = fs.fit_transform(X_train, Y_train)\n",
    "    scores = abs(cross_val_score(linear_reg, X_train_fs, Y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "    print (i,scores.mean())\n",
    "    results = np.append(results, scores.mean())\n",
    "    \n",
    "optimal_percentile = np.where(results == results.min())[0]\n",
    "index = optimal_percentile.item(0)\n",
    "print (\"\\n\" ,\"Optimal percentile of features:{0}\".format(percentiles[index]), \"\\n\")\n",
    "optimal_num_features = int(percentiles[index]*len(Com_x.columns)/100)\n",
    "print (\"Optimal number of features:{0}\".format(optimal_num_features), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20428653c88>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEKCAYAAAAmfuNnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8XXWd//HXO3vSZm3TNklXoAVaKEsXQREQWQoCZaRsKgOIoiigzuAIM4wI+htlcBQQXBCKKAgoilMRKKXsykAXoFCWtpQu6d4mTdMlSZN8fn+ck/Y23Nycpr33Zvk8H4/7yD3fe5bPyWnvJ9/v+Z7vV2aGc845l2wZ6Q7AOedc3+AJxznnXEp4wnHOOZcSnnCcc86lhCcc55xzKeEJxznnXEp4wnHOOZcSnnCcc86lhCcc55xzKZGV7gDSaeDAgTZy5Mh0h+Gccz3KvHnzNppZ+d5u16cTzsiRI5k7d266w3DOuR5F0vKubOdNas4551LCE45zzrmU8ITjnHMuJTzhOOecSwlPOM4551LCE45zzrmU8ITjnHMuJTzhdMF7a7fw30+9R932nekOxTnneoykJhxJUyS9L2mJpOvifH68pPmSmiVNa/fZU5I2S3q8XfmD4T7fljRdUnZYfqKkOklvhK/vJuu8lm/azs+f/4DlNduSdQjnnOt1kpZwJGUCdwGnA2OBiySNbbfaCuBS4PdxdnErcHGc8geBQ4DDgXzgSzGfvWRmR4avm/ftDDpWVZIPwOrNDck6hHPO9TrJrOFMBpaY2VIzawIeBqbGrmBmy8xsAdDafmMzmw3Uxyl/wkLAa8DQpESfQEVxHgCrN+9I9aGdc67HSmbCqQJWxixXh2X7RdiUdjHwVEzxsZLelPSkpHEdbHeFpLmS5m7YsKFLxy7rl0NuVoYnHOec2wvJTDiKU2b7cf8/B140s5fC5fnACDM7AvgZ8Jd4G5nZ3WY20cwmlpfv9WCnAEiiqiSfNXXepOacc1ElM+FUA8NilocCq/fHjiXdCJQD/9JWZmZbzGxr+P4JIFvSwP1xvHgqSvJY5TUc55yLLJkJZw4wWtIoSTnAhcCMfd2ppC8BpwEXmVlrTPkQSQrfTyY4t037eryOVBbns6bOE45zzkWVtIRjZs3AVcBM4F3gD2a2UNLNks4GkDRJUjVwHvArSQvbtpf0EvBH4NOSqiWdFn70S2Aw8Eq77s/TgLclvQncAVwYdixIioqSfNbXN9LU/JH+Ds455+JI6gRsYdPWE+3Kvhvzfg4d9DIzs092UB43ZjO7E7izy8HupaqSPMxg3ZYGhpUVpOqwzjnXY/lIA11UuetZHG9Wc865KDzhdFFFcZhw/D6Oc85F4gmniypL2h7+9K7RzjkXhSecLirIyaKkINub1JxzLiJPOPsg6BrtNRznnIvCE84+qCzJ8xqOc85F5AlnH1SW5PtoA845F5EnnH1QWZJPfUMz9Q0+EZtzznXGE84+aJumwO/jOOdc5zzh7IMqf/jTOeci84SzDyp85k/nnIvME84+GFyYS4bwUaOdcy4CTzj7ICszg8FFPi+Oc85F4QlnH1WW5Ps9HOeci8ATzj6q9KmmnXMuEk84+6iyOI81mxtobU3aXG/OOdcreMLZR5Ul+TS1tLJpW1O6Q3HOuW7NE84+anv40+/jOOdcYp5w9lHbzJ/eNdo55xLzhLOP2kYbWOUPfzrnXEJ7lXAklUoavxfrT5H0vqQlkq6L8/nxkuZLapY0rd1nT0naLOnxduWjJL0qabGkRyTlhOW54fKS8PORe3NuXVVSkE1edoY3qTnnXCc6TTiSnpdUJKkMeBO4T9JPImyXCdwFnA6MBS6SNLbdaiuAS4Hfx9nFrcDFccpvAX5qZqOBWuDysPxyoNbMDgJ+Gq6XdJLCrtGecJxzLpEoNZxiM9sCfBa4z8wmACdH2G4ysMTMlppZE/AwMDV2BTNbZmYLgNb2G5vZbKA+tkySgJOAR8Oi+4FzwvdTw2XCzz8drp90lcX53qTmnHOdiJJwsiRVAOcDj3e2cowqYGXMcnVYti8GAJvNrDnOPncdL/y8Llw/6SpL8ljjTWrOOZdQlIRzMzAT+MDM5kg6AFgcYbt4tYt9fToy0T4jHU/SFZLmSpq7YcOGfQwnUFGcz/r6RhqbW/bL/pxzrjfqNOGY2R/NbLyZXRkuLzWzcyPsuxoYFrM8FFjdtTB32QiUSMqKs89dxws/LwZq2u/AzO42s4lmNrG8vHwfwwm09VRbV9e4X/bnnHO9UZROA2MkzZb0drg8XtINEfY9Bxgd9irLAS4EZuxLsGZmwHNAW4+2S4D/Dd/PCJcJP382XD/p2p7FWe0dB5xzrkNRmtR+DVwP7AQIb/Jf2NlG4X2Uqwia494F/mBmCyXdLOlsAEmTJFUD5wG/krSwbXtJLwF/JLj5Xy3ptPCj7wD/ImkJwT2ae8Pye4EBYfm/AB/php0sFSU+2oBzznUmq/NVKDCz19p1+GruaOVYZvYE8ES7su/GvJ9D0CwWb9tPdlC+lKAHXPvyBoLElXKVxW2jDXhPNeec60iUGs5GSQcS3oAPH9Bck9Soepj8nExKC7J9IjbnnEsgSg3n68DdwCGSVgEfAp9PalQ9UGVJvneNds65BBImHEkZwEQzO1lSPyDDzOoTbdNXVRTns7Jme7rDcM65bithk5qZtRLc+MfMtnmy6VhVSZ53GnDOuQSi3MOZJelaScMklbW9kh5ZD1NZkk99YzNbGnamOxTnnOuWotzD+WL48+sxZQYcsP/D6bkq2ubF2dxA0ZDsNEfjnHPdT6cJx8xGpSKQnq6q7Vmcuh0cPKQwzdE451z302nCkZQNXAkcHxY9D/zKzLztKEZF+CyO38dxzrn4ojSp/QLIBn4eLl8cln0pWUH1RIMKc8nMEGt8mgLnnIsrSsKZZGZHxCw/K+nNZAXUU2VlZjCkyHuqOedcR6L0UmsJRxoAIJyewMfhj6OiOM9HG3DOuQ5EqeF8G3hO0lKCOWdGAJclNaoeqrIknzdWbk53GM451y1F6aU2W9Jo4GCChPOemfnEL3FUlOTx5Ns7aG01MjJSMru1c871GFHmw/k6kG9mC8zsTaBA0teSH1rPU1WSz84WY+M2z8fOOddelHs4XzazXe1EZlYLfDl5IfVcu7tGe08155xrL0rCyVDMZDiSMoGc5IXUc1X6RGzOOdehKJ0GZgJ/kPRLgiFtvgo8ldSoeqiqEn/40znnOhIl4XwHuIJgtAEBTwP3JDOonqo4P5v87ExvUnPOuTii9FJrBX4paTowDlhlZv4cThySqCzJY02d13Ccc669Du/hSPqlpHHh+2LgDeC3wOuSLkpRfD1OZUm+N6k551wciToNfNLMFobvLwMWmdnhwATg36LsXNIUSe9LWiLpujifHy9pvqRmSdPafXaJpMXh65KwrFDSGzGvjZJuCz+7VNKGmM/SMtZbZXE+q+u8Sc0559pL1KTWFPP+FOCPAGa2NqbTWofC3mx3hdtWA3MkzTCzd2JWWwFcClzbbtsy4EZgIkFHhXnhtrXAkTHrzQP+HLPpI2Z2VafBJVFFSR4b6htpbG4hNysznaE451y3kqiGs1nSmZKOAj5B2DNNUhaQH2Hfk4ElZrbUzJqAh4GpsSuY2TIzWwC0ttv2NGCWmdWESWYWMCV2hXD0g0HASxFiSZnKsKfaWq/lOOfcHhIlnK8AVwH3Ad80s7Vh+aeBv0XYdxWwMma5OiyLIsq2FxHUaCym7FxJCyQ9KmlYxGPtV7u7RnvCcc65WB02qZnZItrVKsLymQTP5nQmXrubxSnr6rYXEszN0+avwENm1ijpq8D9wEkf2bF0BUE3b4YPHx4xnOgqiv3hT+eciyfKSANdVQ3E1jKGAqv3x7aSjgCyzGxeW5mZbYoZVPTXBJ0bPsLM7jaziWY2sby8PGI40bU1qXnXaOec21MyE84cYLSkUZJyCGokMyJuOxM4VVKppFLgVPasVV0EPBS7gaSKmMWzgXe7HPk+yMvOpKxfDqu8Sc055/YQZaSBLjGzZklXESSKTGC6mS2UdDMw18xmSJoEPAaUAmdJusnMxplZjaTvEyQtgJvNrCZm9+cDZ7Q75DWSzgaagRqC3m9p4Q9/OufcR3WacCTlAucCI2PXN7ObO9vWzJ4AnmhX9t2Y93MImsvibTsdmN7BZwfEKbseuL6zmFKhsjifZZu2pTsM55zrVqI0qf0vQXfmZmBbzMt1IBhtwJvUnHMuVpQmtaFm9pHeaq5jlSV5bG1sZkvDTorystMdjnPOdQtRajj/kHR40iPpRXZPxOb3cZxzrk2UhHMcwdAy74cPVb4laUGyA+vJdnWN9mY155zbJUqT2ulJj6KXaZv5c5XXcJxzbpdOazhmthwoAc4KXyVhmevAoMI8MjPkTWrOORej04Qj6RvAgwQDZQ4CHpB0dbID68kyM8SQojzW+ACezjm3S5QmtcuBj5nZNgBJtwCvAD9LZmA9XWVJnjepOedcjCidBgTETindQvzBNV2MypJ8H23AOediRKnh3Ae8KumxcPkc4N7khdQ7VBTns7ZuDa2tRkaG52fnnOs04ZjZTyQ9T9A9WsBlZvZ6sgPr6apK8tjZYmzc2sigorx0h+Occ2nXYcKRVGRmW8LpnpeFr7bPytoNpunaaXv4c9XmHZ5wnHOOxDWc3wNnAvPYc/IzhcsfGUDT7VYZM/PnUft/njfnnOtxEs34eWb4c1Tqwuk9qnwiNuec20OU53BmRylzeyrKz6IgJ9O7RjvnXCjRPZw8oAAYGM662dbVqgioTEFsPZqkoGu0j6fmnHNA4ns4XwG+SZBc5rE74WwB7kpyXL1CRXEeq71JzTnngMT3cG4Hbpd0tZn5qAJdUFWSz7tr6tMdhnPOdQtRnsP5maTDgLFAXkz5b5MZWG9QWZLPxq2NNOxsIS87M93hOOdcWnWacCTdCJxIkHCeIJiu4GXAE04nKoqD/Ly2roGRA/ulORrnnEuvKGOpTQM+Daw1s8uAI4DcpEbVS7R1jfb7OM45Fy3h7DCzVqBZUhGwnogPfUqaEs4UukTSdXE+P17SfEnNkqa1++wSSYvD1yUx5c+H+3wjfA0Ky3MlPRIe61VJI6PEmEwVMQ9/OudcXxdl8M65kkqAXxP0VtsKvNbZRpIyCXqznQJUA3MkzTCzd2JWWwFcClzbbtsy4EZgIsGoBvPCbWvDVT5vZnPbHfJyoNbMDpJ0IXALcEGE80uatia1Nf4sjnPOReo08LXw7S8lPQUUmdmCCPueDCwxs6UAkh4GpgK7Eo6ZLQs/a2237WnArLbx2iTNAqYADyU43lTge+H7R4E7JcnMrONNkisvO5MB/XK8Sc0550j84OfRiT4zs/md7LsKWBmzXA18LGJc8batilm+T1IL8CfgB2FS2bWNmTVLqgMGABsjHjMpKkvyWeVNas45l7CG8z/hzzyCpq03CR7+HA+8SjBdQSLxJoGJWttItO3nzWyVpEKChHMxQY+5SMeTdAVwBcDw4ckfVbOyJI+lG7Yl/TjOOdfdddhpwMw+ZWafApYDR5vZRDObABwFLImw72pgWMzyUGB1xLg63NbMVoU/6wlGtJ7cfhtJWUAx8JEpFMzs7vBcJpaXl0cMp+sqivNZvXkHaWzZc865biFKL7VDzOyttgUzexs4MsJ2c4DRkkZJygEuBGZEjGsmcKqk0nAct1OBmZKyJA0EkJRNMH3C2+E2M4C23mzTgGfTef+mTVVJPtuaWtjS0JzuUJxzLq2i9FJ7V9I9wAMETVRfAN7tbKPwPspVBMkjE5huZgsl3QzMNbMZkiYBjwGlwFmSbjKzcWZWI+n7BEkL4OawrB9B4skO9/kMQe85CKa9/p2kJQQ1mwuj/QqSq6Ik6Km2evMOivOz0xyNc86lT5SEcxlwJfCNcPlF4BdRdm5mTxCMThBb9t2Y93MImsvibTsdmN6ubBswoYP1G4DzosSVSpUx8+IcWlGU5miccy59onSLbgB+Gr7cXqrcNdW091RzzvVtibpF/8HMzpf0FnF6e5nZ+KRG1kuUF+aSlSFW+8Ofzrk+LlENp60J7cxUBNJbZWaIIcV5PtqAc67PSzQfzprw5/LUhdM7VRbn+3hqzrk+L1GTWj3xH9QUYGbmd8AjqizJY+7y2s5XdM65XixRDacwlYH0ZhUl+axdsIaWViMzI96ACM451/tF6RYNQDgNQOyMnyuSElEvVFmST3OrsXFrI4OL8jrfwDnneqFORxqQdLakxcCHwAvAMuDJJMfVq1SFD3+u8o4Dzrk+LMrQNt8HjgEWmdkogtk//57UqHqZiuK2idg84Tjn+q4oCWenmW0CMiRlmNlzRBtLzYV2jTbgPdWcc31YlHs4myX1JxjS5kFJ6wEfiXIvFOVl0S8n05vUnHN9WpQazlRgB/At4CngA+CsZAbV20iisiSfNT7zp3OuD0v0HM6dwO/N7B8xxfcnP6TeqaLEH/50zvVtiWo4i4H/kbRM0i2S/L7NPqgqyfNOA865Pi3RjJ+3m9mxwAkE88vcJ+ldSd+VNCZlEfYSlcX5bNrWRMPOlnSH4pxzadHpPRwzW25mt5jZUcDngH8iwgRsbk8Vu+bF8WY151zfFOXBz2xJZ0l6kOCBz0XAuUmPrJepDB/+9FGjnXN9VaJOA6cAFwGfAV4DHgauCGfddHtp90RsnnCcc31Toudw/h34PXCtmdWkKJ5ea0hxWMPxJjXnXB+VaLToT7Uvk3SFmd2d3JB6p7zsTAb2z/Geas65PivKg5+xvro3K0uaIul9SUskXRfn8+MlzZfULGlau88ukbQ4fF0SlhVI+puk9yQtlPSjmPUvlbRB0hvh60t7eW5JV1mS701qzrk+K/L0BKHIk7lIygTuAk4BqoE5kmaY2Tsxq60ALgWubbdtGXAjMJFgErh5kmYAjcCPzew5STnAbEmnm1nb6NWPmNlVe3lOKVNZnM+SDVvTHYZzzqXF3tZw9mZIm8nAEjNbamZNBJ0OpsauYGbLzGwB0Npu29OAWWZWY2a1wCxgipltDwcPJdznfGDoXp5D2lSED3+axZtI1Tnnerco3aK/IalIkoCbwiawUyPsuwpYGbNcHZZF0em2kkoIEuDsmOJzJS2Q9KikYRGPlTJVJflsb2phyw4f+9Q51/dEqeF80cy2AKcC5cBlwI8SbwLEb36L+qd9wm0lZQEPAXeY2dKw+K/ASDMbDzxDB+O+SbpC0lxJczds2BAxnP2jwrtGO+f6sCgJp+3L/wzgPjN7k2j3cqqB2FrGUGB1xLg62/ZuYLGZ3dZWYGabzKwxXPw1MCHejs3sbjObaGYTy8vLI4azf+x6+NNHjXbO9UFREs48SU8TJJyZkgr56D2XeOYAoyWNCm/wXwjMiBjXTOBUSaWSSglqVzMBJP0AKAa+GbuBpIqYxbPphsPvVJX4zJ/Oub4rSi+1ywlm+FxqZtvDHmSXdbaRmTVLuoogUWQC081soaSbgblmNkPSJOAxoBQ4S9JNZjbOzGokfZ8gaQHcHJYNBf4DeA+YH9xW4k4zuwe4RtLZBJPD1RD0futWBvbPJTtTrPJpCpxzfVCUhHMs8IaZbZP0BeBo4PYoOzezJ4An2pV9N+b9HDroZWZm04Hp7cqq6aA5z8yuB66PEle6ZGSIIcV53qTmnOuTojSp/QLYLukI4N+A5cBvkxpVL1ZRnO9Nas65PilKwmm24MGRqcDtZnY7UJjcsHqvKp/50znXR0VpUquXdD1wMfDJcASB7OSG1XtVFOexdksDLa1GZkbkgRucc67Hi1LDuYBgSJkvmtlaggcwb01qVL1YZUk+La3G+nqv5Tjn+pYoM36uBR4EiiWdCTSYmd/D6aLdXaM94Tjn+pYoQ9ucTzAB23nA+cCr7Ud2dtFVhA9/escB51xfE+Uezn8Ak8xsPYCkcoKhYx5NZmC9VWVYw0ll1+jWVqO6dgeL19ezaN1WFq+rZ9O2Jm45d/yuieGccy7ZoiScjLZkE9rE3o8y7UJFedn0z81KSpNaW2JZtK6exeuDxLJofT1L1m+lYefuwSEGF+VSu20n/++Jd/nZRUft9ziccy6eKAnnKUkzCQbLhKATwRMJ1nedqAynKegqM2NlTZBYFq2vZ8m6rXETy5CiPEYP7s/nJo9g9OD+jBncn4MGFVKcn81PZi3ijtmLufiYEUweVbY/Tss55xLqNOGY2bclfRY4juAp/7vN7LGkR9aLVRTnszpik5pZUGt5a1UdC6rreGvVZt6qrmNLw+4pDmITy5jB/Rkdk1g6cuUJB/Lo3JV8b8ZC/nr1cd5F2zmXdAkTTvjMzUwzOxn4c2pC6v0qS/J5a1XdR8rNjLVbGoLEUl3HglV1vFW9mdrtOwHIzhSHDCnizCMqOayymIOHFHLQoP4JE0tH8nMyuf6MQ7n6odd5ZM5KPvex4ft8Xs45l0jChGNmLZK2Syo2s49+Q7ouqSrJo2ZbEytrtrNoXX1YcwlqMBu3BjMsZGaIMYMLOXXsEA4fWsz4oUGCyc3K3G9xnDm+gt/933J+/PT7fObwCooL/Hle51zyRLmH0wC8JWkWsK2t0MyuSVpUvVzbRGyf/O/nAMgQHDSoPyeMKWf80GIOH1rM2Ioi8rL3X3KJRxI3njWWs372MrfNXsSNZ41L6vGcc31blITzt/Dl9pNPHTKIS44dwfAB/RgfJpd+uVEuxf43rrKYCycP57evLOdzk4czerAPk+ecSw4F43LG+SB43qbczN5pV34YsM7MUjs/cxJMnDjR5s6dm+4w0q5mWxMn3vocRwwr4bdfnEw4z5BzzsUlaZ6ZTdzb7RI9T/MzIN4czFVEnA/H9Qxl/XL41iljeGnxRma9sy7d4TjneqlECedwM3uhfaGZzQTGJy8klw5fOGYEowf15wd/e5eGnS3pDsc51wslSjiJuix5d6ZeJjszgxvPGseKmu3c+/KH6Q7HOdcLJUo4iyWd0b5Q0unA0uSF5NLluNEDOXXsYO56bglr63w0a+fc/pUo4XwLuE3SbyRdHb7uJ7h/843UhOdS7YbPjKW51fjRk++mOxTnXC/TYcIxs0XA4cALwMjw9QIwPvzM9ULDBxTw5U+O4i9vrGbe8pp0h+Oc60USjvpsZo1mdp+Z/Wv4mm5mkdtaJE2R9L6kJZKui/P58ZLmS2puP8eOpEskLQ5fl8SUT5D0VrjPOxT24ZVUJmlWuP4sSaVR43R7+tqJBzG4KJfvzXiH1tb43eadc25vJW2agXActruA04GxwEWSxrZbbQVwKfD7dtuWATcCHwMmAzfGJJBfAFcAo8PXlLD8OmC2mY0GZofLrgv65WZx/emH8taqOv44b2W6w3HO9RLJnNdmMrDEzJaaWRPwMDA1dgUzW2ZmC4DWdtueBswysxozqwVmAVMkVQBFZvaKBU+s/hY4J9xmKnB/+P7+mHLXBVOPrGTCiFJunfk+Wxp2pjsc51wv0GHCkVSU4LMoQwtXAbF/HleHZVF0tG1V+D7ePgeb2RqA8OegeDuWdIWkuZLmbtjQ4wdLSBpJ3HT2ODZta+KOZxanOxznXC+QqIbzfNsbSbPbffaXCPuONz5K1BsCHW27L/sMVja728wmmtnE8vJ4Aym4NodVFXPBxGH85h/LWLJ+a7rDcc71cIkSTuyXe/spIaMMtlUNDItZHgqsjhhXR9tWh+/j7XNd2ORG+DN2WmzXRdeedjD5OZl8//F36GjcPeeciyJRwrEO3sdbjmcOMFrSKEk5wIXAjIhxzQROlVQadhY4lWAiuDVAvaRjwt5p/wz8b7jNDKCtN9slMeVuHwzsn8s3Pj2aFxZt4Nn3PIc757ou0Zj4gyT9C0Ftpu094XKnbVFm1izpKoLkkQlMN7OFkm4G5prZDEmTgMeAUuAsSTeZ2Tgzq5H0fYKkBXCzmbU9FHIl8BsgH3gyfAH8CPiDpMsJer+dF+UX4Dp3ycdH8tBrK/j+4+9w3OiB+3USOOdc35FoeoIbE21oZjclJaIU8ukJonth0QYumf4a151+CF894cB0h+OcS6OuTk/QYQ0nUUIJayauDzlhTDknHzqIn81ezGePqmJQUV66Q3LO9TCRn8ORNFbSzZIWEzx86fqYGz4zlp0txi1PvZ/uUJxzPVDChCNphKTrJL0J/A74GnBKV6pSrucbObAfXzxuFH+aX83rK2rTHY5zrodJ9ODnP4AnCOa+mWZmE4B6M1uWothcN3TVSQcxqDCX7/3Vx1lzzu2dRDWcDUAhMJjdvdL8G6aP65+bxXemHMKbKzfz2Our0h2Oc64HSTQ9wVSC6QnmAzdJ+hAolTQ5VcG57umfjqpi/NBibp35PtubmtMdjnOuh+hseoK6cEqCU4BjCEZwvk2SDyHch2VkiP88cyxrtzTw6xd9OmrnXDSRe6mZ2Tozu8PMPg4cl8SYXA8waWQZZxw+hF++8IFPR+2ci6TD53AkdTYMzdn7ORbXw1w35VCeeWc9P376fX583hHpDsc5180lGtrmWIIpAh4CXiXagJ2uDxk+oIDLjhvJ3S8u5dKPj+SwquJ0h+Sc68YSNakNAf4dOAy4HTgF2GhmL5jZC6kIznV/X//UQZQV5HCzjybtnOtEol5qLWb2lJldQtBhYAnwvKSrUxad6/aK8rL51iljeO3DGmYuXJfucJxz3VhnIw3kSvos8ADwdeAO4M+pCMz1HBdOGsaYwf354ZPv0tjcku5wnHPdVKKRBu4H/gEcDdxkZpPM7Ptm5k/7uT1kZWbwH58Zy/JN2/ndK8vTHY5zrptKVMO5GBgDfAP4h6Qt4ate0pbUhOd6ihPGlHPCmHJun72Ymm1N6Q7HOdcNJbqHk2FmheGrKOZVaGZFqQzS9Qw3fOZQtje1cPszi9IdinPd1rbGZlZs2k5zS2u6Q0m5RN2indsrowcXctHkYTzw6gouPnYEBw0qTHdIzqXMzpZWNtQ3snZLA+u3NLC2roF19Y2sq2tgXX2wvH5LI/WNwXBQhwwp5AfnHMbEkWVpjjx1Opzxsy/wGT/3v01bGznxx88zcUQp913mw+653mVHUwtvVm9m/opaqmt3xCSTRjZta6T912nqQ5GZAAAViklEQVR2phhUmMfgolyGFOcxqDCPIcV55GVlcPeLS1ld18AFE4dx3emHUNovJz0n1QX7fcZP57piQP9crj7pIP7rifd4cdEGjh9T3vlGznVTG+obmbe8hrnLapmzvJaFq+poDqflGNg/Z1cCObyqmMFFeQwuymNIUR6DinIZUpRHaUEOGRnxn5k/b+Iw7pi9mHte/pCn31nL9WccyrSjh3a4fm/gNRyv4ex3jc0tnPKTF8nPzuRv1xxHVmbkIfucS5vWVuODDVuZu7yWuctqmbu8huWbtgOQm5XBEcNKmDiilIkjSzl6eCklBfunRvLe2i3c8NjbzF1ey6SRpfzgnMM5eEj3bo7uag0nqQlH0hSCUQoygXvM7EftPs8FfgtMADYBF5jZMkk5wK+AiUAr8A0ze15SIfBSzC6GAg+Y2TclXQrcCrR1277TzO5JFJ8nnOR58q01XPngfP7rnw7ncx8bnu5wXJrtbGllzeYGVtZuZ2XNdlZv3kG/3CzKC3MpL8xlUGEe5YW5lORnp+wv/IadLSyormPu8hrmLatl3opaNm/fCcCAfjlMCJPLxJFlHFZZTE5W8v5wam01Hp1XzQ+ffJf6hmYu/+QovvHp0RTkdM9GqG7XpCYpE7iLYEicamCOpBlm9k7MapcDtWZ2kKQLgVuAC4AvA5jZ4ZIGAU9KmmRm9cCRMceYx54Poj5iZlcl65xcdFMOG8LkkWX8ZNb7nHVEBYV52ekOySWRmbGhvjFMKDtYWbOdFTXbdy2vqdtBlAliszPFwP5BEirvn8ugouBnkJjywuSUy8D+uTS3trK9qYWtjc1sa2xmW2NL8LMpeL+9qXn3Z00te6yzpWEni9dtpSnsKXZAeT9OGzuECSNLmTiilFED+yGlrmkrI0OcP2kYJ48dzI+efJdfvbCUx99cw41njeXUcUNSFkeyJTN9TgaWmNlSAEkPA1OB2IQzFfhe+P5R4E4FV3ksMBvAzNZL2kxQ23mtbUNJo4FB7Fnjcd2EJG4481DOvvPv/Pz5D/jOlEPSHZLbT7Y3NfOn+atYvK4+SCo126mu3UFj857dfMsLcxleVsCkkaUMK6tiWGkBQ8vyGVZaQEVxHg3NQa+uttf6+oaY942sqWtgwao6Nm1tjJSsOpKXnUH/3Cz65WZRkJNF/9xMygtzOe6ggUwcWcaEEaWUdZMb9mX9cvjvaUdw3sRh3PDY21zxu3mcfOggvnf2OIaWFqQ7vH2WzIRTRTDadJtq4GMdrWNmzZLqgAHAm8DUMEkNI2hyG0ZMwgEuIqjRxP5TPFfS8cAi4Ftm5hPFpdH4oSV89qgq7n35Qz43eTjDynr+f5i+rLmllUfmruS2Zxazob6RorwshpUVMHpQIScdMohhZQUMKy1gWFk+Q0sLyMvOTLi//plBIhg1sF/C9VpajU3bGvdIRhu3NpKdkUG/3Cz65WbSLyeLgtxM+u9KKsFyv5wsMnvgTfhJI8t4/JrjmP7yh9z2zGJO+cmLXPPp0Xzpk6PI7uI90eaWVtbUNeyqfY4eXMiEEaX7OfLEkplw4l3l9n+ndLTOdOBQYC6wnGCInfZzGV9IMBpCm78CD5lZo6SvAvcDJ30kKOkK4AqA4cP93kKyfXvKwTzx9hpueeo97vzc0ekOx3WBmTFz4Tr+e+Z7LN2wjYkjSvnlF45mwojUPD+SmRF0LR5UmJeS43UX2ZkZfOWEAznziEpumrGQW556jz/Pr+YH5xzGxw4Y8JH1zYxN25p2JZTq2j2bNldvbqAlpqr4xU+MSnnCSVqnAUnHAt8zs9PC5esBzOyHMevMDNd5RVIWsBYob1drQdI/gC+13f+RdATwRzMb08GxM4EaM0s4QYt3GkiNn8xaxB2zF/OnK49N2ZeU2z/mLqvhh0++x7zltRxY3o/vTDmEU8YOTun9DRd45p113DhjIas272DahKGMrSja1QljZc0OVtZuZ3vTnoPnDuyfy/CyfIaVFTA8rIEOLctneFkBQ4ryutyDtNt1GgDmAKMljSLoOXYh8Ll268wALgFeAaYBz5qZSSogSIbbJJ0CNLfrbHARwcRwu0iqMLM14eLZwLv7/Yxcl3z1hAN4ZM4Kbn78XR678uO9+jmD3mLJ+npueep9Zr2zjkGFufzws4dz3oSh3sU9jU4eO5iPHzSAnz27hF+/uJRH51XTLyczSCYDCvjEQQP3SC5DSwvIz0ncrJlqSUs44T2Zq4CZBN2ip5vZQkk3A3PNbAZwL/A7SUuAGoKkBEFngJmSWgmS1cXtdn8+cEa7smsknU3Q9FYDXJqE03JdUJCTxbdPO4Rr//gmf12wmqlHVqU7JNeBdVsauO2ZRTwyZyUFOVlce+oYvnjcqG7bPbevKcjJ4jtTDuFLx41CEqUF2T2qtukPfnqTWkq0thpn3/UyNVubmP2vJ3a7v7z6uvqGndz94lLueelDmltb+fzHRnD1SQcxoH9uukNz3VB3bFJzbpeMDHHDZ8Zy4d3/x70vL+Wqk0anOyQHNDW38vtXl3PHs0uo2dbEmeMr+PZpBzNiQOKeY851hScclzLHHDCA08YN5ufPf8D5E4cxqKhv9TrqTsyMxxes4cdPv8/yTds59oABXHf6IRwxrCTdoblezBOOS6nrTz+UZ997gf95ehG3TBuf7nD6lM3bm5i/opZ5y2t57r0NvLNmC4cMKeS+yyZx4pjyHnUvwPVMnnBcSo0c2I9Ljh3JvX//kNeW1ex6aK8wLyt8iC94aK9fTvBAX9sT4v3zdpf3z82iuCCb4nwfLqcjZsaHG7cxd3kt85fXMnd5LUvWbwWC51rGVRZx67TxfPbooT3ywUjXM3nCcSn3zVPGkJkhVtc1sK2xma0Nzaze3BCOgRWMf9Wws/PZEE8/bAjfOmUMYwZ375F1U6FhZwtvrapjXjjS8fwVtbum+i7Ky2LCiFLOObKSCSPKOGJYsfc6c2nh/+pcyvXPzeL6Mw5NuE5zS+uuARe3NsYMwtjYzNbGFj7YsJXfvbKcpxau5ewjKvnmyWM6HSIl1cyMbU0tbAyHYtm4tZENW5vYWN9I7fYmMiRyszPIzcokNysjeGXHvM/KDD/fvU5euD7AwtVbgrlaltfy9qo6drYEPU4PGNiPkw4ZxMQRpUwYUcqB5f392SfXLXi3aO8W3WPVbmvi7peW8pu/L6OppZVzj67i6pNGp2TMtpU121lT17ArkWysD5PJ1mC8r7byeDU1CYrzs2ltNRqbWz8y6OXeyMnK4IihxRw9opSJI8o4eniJd2V2Sdct58Pp7jzh9A4b6hv5xfMf8MCryzEzLpg0jKs+NZohxfuvF5yZsWjdVv721hqeeGvNrvshbTIUjPTbNrT+wP65DOyfE/7MZWBhsFzeP5eyfjl7PLFvZjS1BImncWcrjc0tH33f3Erjzt3vm1taGTOkkHGVRbtqPM6liiecLvCE07usqdvBXc8t4ZE5K5HExceM4MoTD2RgF//iNzPeW1vPE2GS+WDDNjIEk0eVMWXcEA4c1H9XQinrl+M3312f4QmnCzzh9E4ra7Zzx+zF/Pn1VeRkZnDpJ0byleMPiDQlsJnx7prdSWbpxiDJfGzUAM4YX8GUcUMoL/QmK9e3ecLpAk84vdvSDVu5ffZiZry5mv45WVz+yVF88bhRFLWbfdTMeGfNljDJrOXDMMkcc8AAzji8gtM8yTi3B084XeAJp294f209tz2ziCffXktxfjZfOeEALjl2JB9u3LarJrNs03YyBMceuDvJdLUpzrnezhNOF3jC6VveXlXHT2Yt4tn31pOTmUFTSyuZGeLYXTWZwd7Dy7kIfPBO5zpxWFUx0y+dxPwVtfxpXjWHVRVz2rgh3WY+e+d6O084rs85engpRw9P7dS6zjnw6fucc86lhCcc55xzKeEJxznnXEp4wnHOOZcSnnCcc86lhCcc55xzKeEJxznnXEp4wnHOOZcSfXpoG0kbgOV7sclAYGOSwukJ/Pz9/Pvy+YP/DtrOf4SZle/txn064ewtSXO7Mn5Qb+Hn7+ffl88f/Hewr+fvTWrOOedSwhOOc865lPCEs3fuTncAaebn37f19fMH/x3s0/n7PRznnHMp4TUc55xzKeEJJyJJUyS9L2mJpOvSHU+ySRom6TlJ70paKOkbYXmZpFmSFoc/e/XEMpIyJb0u6fFweZSkV8Pzf0RSr529TVKJpEclvRf+Ozi2L11/Sd8K/+2/LekhSXm9+fpLmi5pvaS3Y8riXm8F7gi/DxdIOjrKMTzhRCApE7gLOB0YC1wkaWx6o0q6ZuBfzexQ4Bjg6+E5XwfMNrPRwOxwuTf7BvBuzPItwE/D868FLk9LVKlxO/CUmR0CHEHwe+gT119SFXANMNHMDgMygQvp3df/N8CUdmUdXe/TgdHh6wrgF1EO4AknmsnAEjNbamZNwMPA1DTHlFRmtsbM5ofv6wm+bKoIzvv+cLX7gXPSE2HySRoKfAa4J1wWcBLwaLhKrz1/SUXA8cC9AGbWZGab6UPXn2BG5HxJWUABsIZefP3N7EWgpl1xR9d7KvBbC/wfUCKporNjeMKJpgpYGbNcHZb1CZJGAkcBrwKDzWwNBEkJGJS+yJLuNuDfgNZweQCw2cyaw+Xe/O/gAGADcF/YpHiPpH70ketvZquAHwMrCBJNHTCPvnP923R0vbv0negJJxrFKesT3fsk9Qf+BHzTzLakO55UkXQmsN7M5sUWx1m1t/47yAKOBn5hZkcB2+ilzWfxhPcqpgKjgEqgH0EzUnu99fp3pkv/FzzhRFMNDItZHgqsTlMsKSMpmyDZPGhmfw6L17VVncOf69MVX5J9Ajhb0jKCJtSTCGo8JWETC/TufwfVQLWZvRouP0qQgPrK9T8Z+NDMNpjZTuDPwMfpO9e/TUfXu0vfiZ5wopkDjA57qOQQ3DyckeaYkiq8X3Ev8K6Z/STmoxnAJeH7S4D/TXVsqWBm15vZUDMbSXC9nzWzzwPPAdPC1Xrz+a8FVko6OCz6NPAOfeT6EzSlHSOpIPy/0Hb+feL6x+joes8A/jnsrXYMUNfW9JaIP/gZkaQzCP7CzQSmm9n/S3NISSXpOOAl4C1238P4d4L7OH8AhhP8pzzPzNrfaOxVJJ0IXGtmZ0o6gKDGUwa8DnzBzBrTGV+ySDqSoMNEDrAUuIzgj9Q+cf0l3QRcQNBj83XgSwT3KXrl9Zf0EHAiwYjQ64Abgb8Q53qHSfhOgl5t24HLzGxup8fwhOOccy4VvEnNOedcSnjCcc45lxKecJxzzqWEJxznnHMp4QnHOedcSnjCcUklqUXSG+GIu3+UVJCmOL6ZrmOHx781HHn41nbluZKeCX9HF3Rhv+d054FkJZ3YNtJ2F7bd62u2L8dzyecJxyXbDjM7Mhxxtwn4atQNw1G695dvEgzAmC5fAY42s2+3Kz8KyA5/R490Yb/nEIxgHlnMk/LdXbqvmdvPPOG4VHoJOAhA0hckvRb+Zf+rtuQiaaukmyW9ChwraZKkf0h6M1y/UMEcNbdKmhPOxfGVcNsTJT2v3XO4PBg+CX0NwXhYz0l6Llz3F5LmhrWOm9oClHRGuO3L4XwfbfPg9FMwX8iccDDLj4wWHh7r1rA291ZbjUXSDIKxuF6NrcVIGgQ8ABwZ/h4OlDRB0guS5kmaGTOsyJfDY78p6U/hE/AfB84Gbo3Z/nlJE8NtBoZD8yDp0rCG+Vfg6bDs2zG/w5tizvNv4XHejlfrknSNpHfC7R7ei99P3HXC6/nj8He2QNLVHVyzUyW9Iml+eC79w/IpbdcM+Gwn/wZdOpmZv/yVtBewNfyZRTAsxpXAocBfCf6yB/g58M/hewPOD9+3PeE+KVwuCvdzBXBDWJYLzCUYZPFEglF9hxL8MfUKcFy43jJgYExcZeHPTOB5YDyQRzAC7qjws4eAx8P3/0XwVDlACbAI6NfuXM8FZoX7HEzwZHZF7O8hzu/nxJhjZAP/AMrD5QsIRrUAGBCzzQ+Aq8P3vwGmxXz2PMEcLhA8Mb4sfH8pwfhXbed9KsH89Ap/V48TTEdwLvDrmP0Vx4l5NZDb9rtI9Ptpd34drXMlwZh9We2uza5rFp7Li22/c+A7wHdjrtno8Fz+0HY8f3W/V0+pWrueK1/SG+H7lwjGZ7sCmADMkQSQz+5BAVsIvnwADgbWmNkcAAtHq5Z0KjBeUtuYVsUEXzhNwGtmVh2u9wYwEng5TlznS7qCIIFVEDRLZQBLzezDcJ2Hwlgh+II+W9K14XIewXAfsZOzHQc8ZGYtBIMevgBMIvq4ewcDhwGzwt9LJsHQ+ACHSfoBwRd1f2BmxH3GmmW7h6E5NXy9Hi73J/gdvgT8WNItBF/cL8XZzwLgQUl/IRj6pG1/8X4/sTpa52TglxYO+2/xh8o5huAa/T383eQQ/EFxCMEgm4sBJD3A7mvmuhlPOC7ZdpjZkbEFCr4x7jez6+Os3xB+YUPwF2u8sZdE8Bf+Hl+6CsY8ix3XqoU4/8YljQKuJag51Ur6DcGXX7wh12OPea6Zvd/JOvtCwEIzOzbOZ78BzjGzNyVdSlBziKeZ3U3lee0+29buWD80s199JAhpAnAG8ENJT5vZze1W+QxBbehs4D8ljaOD34+kwe2OGW+djq7zHqsRJMyL2m17ZIRtXTfh93BcOswGpoX3MNrmTR8RZ733gEpJk8L1ChXc8J4JXKlg+gQkjVEwOVgi9UBh+L6I4Mu3LvxCbJvn5D3gAAUTzkHQpNVmJnB1+OWIpKPiHONF4ILwnkQ5wZfya53EFet9oFzSseExssMvc8LY14Tn/PkOzguCZqgJ4ftpdGwm8MWY+yBVkgZJqgS2m9kDBBOQ7TFXvaQMYJiZPUcwOV1sjauz309H6zwNfDW8tkgqi3Nu/wd8QlLbPcACSWMIrtkoSQeG6+2RkFz34jUcl3Jm9o6kG4Cnwy+wncDXgeXt1msKb1r/TFI+sIOg+eUegqay+eGX1wY6n+r3buBJSWvM7FOSXgcWEtwj+nt4vB2SvgY8JWkjeyaL7xOMFr4gPOYy4Mx2x3gMOBZ4k+Cv7n+zYJj/SMLznQbcIamY4P/nbWGc/0kwUvdyghG8276IHwZ+Hd5kn0aQJP4g6WLg2QTHelrSocAr4ff/VuALBJ06bpXUSnBdrmy3aSbwQBifgJ+a2WZJUX4/Ha1zDzAmLN8J/JpgJOL21+xS4CFJueH+bjCzRWHT6N/Ca/YyQbOk64Z8tGjnYkjqb2Zbwy/Eu4DFZvbTdMflXG/gTWrO7enLYWeDhQSdET5yj8M51zVew3HOOZcSXsNxzjmXEp5wnHPOpYQnHOeccynhCcc551xKeMJxzjmXEp5wnHPOpcT/B8krgmD1IPhRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot features percentile VS. MAE scores\n",
    "import pylab as pl\n",
    "pl.figure()\n",
    "pl.xlabel(\"Percentage of features selected\")\n",
    "pl.ylabel(\"MAE Cross-Validation Scores\")\n",
    "pl.plot(percentiles,results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the graph, we can see that the optimal percentile of features is 36 (has the lowest MAE score).\n",
    "#### The optimal number of features is 34."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate our best number of features on the test set and performance ( using MAE ) with the new feature set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute Error of Linear Model (34 features) is 0.102111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "optimal_percentile = 41\n",
    "fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile = optimal_percentile)\n",
    "X_train_fs = fs.fit_transform(X_train, Y_train)\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train_fs, Y_train)\n",
    "X_testfs = fs.transform(X_test)\n",
    "Y_pred = linear_reg.predict(X_testfs)\n",
    "MAEscore = mean_absolute_error(Y_test, Y_pred)\n",
    "print(\"Mean absolute Error of Linear Model (34 features) is %f\" %MAEscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True  True False  True False False False False  True False  True\n",
      " False False  True False  True False  True  True False False False False False\n",
      " False  True  True  True  True False  True False False False  True  True  True\n",
      "  True False  True  True  True  True False False  True  True False False False\n",
      " False False False False False False False  True  True False False False False\n",
      "  True  True  True  True  True  True  True  True False False  True  True False\n",
      " False False False False False False  True False False  True  True False False\n",
      " False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=2, linewidth=80)\n",
    "print (fs.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['population', 'householdsize', 'racepctblack', 'racePctWhite',\n",
       "       'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29',\n",
       "       'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome',\n",
       "       'pctWWage', 'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst',\n",
       "       'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap', 'blackPerCap',\n",
       "       'indianPerCap', 'AsianPerCap', 'OtherPerCap', 'HispPerCap',\n",
       "       'NumUnderPov', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad',\n",
       "       'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu',\n",
       "       'PctEmplProfServ', 'MalePctDivorce', 'MalePctNevMarr', 'FemalePctDiv',\n",
       "       'TotalPctDiv', 'PersPerFam', 'PctFam2Par', 'PctKids2Par',\n",
       "       'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom',\n",
       "       'NumIlleg', 'PctIlleg', 'NumImmig', 'PctImmigRecent', 'PctImmigRec5',\n",
       "       'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig', 'PctRecImmig5',\n",
       "       'PctRecImmig8', 'PctRecImmig10', 'PctSpeakEnglOnly',\n",
       "       'PctNotSpeakEnglWell', 'PctLargHouseFam', 'PctLargHouseOccup',\n",
       "       'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous',\n",
       "       'PctPersOwnOccup', 'PctPersDenseHous', 'PctHousLess3BR', 'MedNumBR',\n",
       "       'HousVacant', 'PctHousOccup', 'PctHousOwnOcc', 'PctVacantBoarded',\n",
       "       'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone', 'PctWOFullPlumb',\n",
       "       'OwnOccLowQuart', 'OwnOccMedVal', 'OwnOccHiQuart', 'RentLowQ',\n",
       "       'RentMedian', 'RentHighQ', 'MedRent', 'MedRentPctHousInc',\n",
       "       'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'NumInShelters',\n",
       "       'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85',\n",
       "       'PctSameCity85', 'PctSameState85', 'LandArea', 'PopDens',\n",
       "       'PctUsePubTrans'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Com_x.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population \t 242.21954906378855\n",
      "racepctblack \t 987.9890616057469\n",
      "racePctWhite \t 1358.8179733182715\n",
      "racePctHisp \t 173.57846535987667\n",
      "numbUrban \t 234.9816321827691\n",
      "medIncome \t 338.6234405271587\n",
      "pctWInvInc \t 809.3145448865988\n",
      "pctWPubAsst \t 761.1655082613166\n",
      "medFamInc \t 368.32143358977146\n",
      "perCapInc \t 216.3737917833643\n",
      "NumUnderPov \t 388.6570377567564\n",
      "PctPopUnderPov \t 591.0771584677361\n",
      "PctLess9thGrade \t 329.19727262332856\n",
      "PctNotHSGrad \t 488.7932602130596\n",
      "PctUnemployed \t 527.6520739411234\n",
      "MalePctDivorce \t 619.9075307836308\n",
      "MalePctNevMarr \t 172.96686684776742\n",
      "FemalePctDiv \t 734.3305543341702\n",
      "TotalPctDiv \t 718.6305617359558\n",
      "PctFam2Par \t 1570.2841035663116\n",
      "PctKids2Par \t 1871.95174159244\n",
      "PctYoungKids2Par \t 1260.794416156771\n",
      "PctTeen2Par \t 1231.0992532763491\n",
      "NumIlleg \t 449.59320757129\n",
      "PctIlleg \t 1847.7568162895536\n",
      "PctNotSpeakEnglWell \t 181.46594943273328\n",
      "PctLargHouseFam \t 271.9211545352287\n",
      "PctPersOwnOccup \t 650.5436057121348\n",
      "PctPersDenseHous \t 459.83327116767236\n",
      "PctHousLess3BR \t 485.27364384897714\n",
      "MedNumBR \t 226.72484959200034\n",
      "HousVacant \t 332.8613035373555\n",
      "PctHousOccup \t 177.41156222594856\n",
      "PctHousOwnOcc \t 486.78987798462333\n",
      "PctVacantBoarded \t 469.179773665973\n",
      "PctHousNoPhone \t 531.6013667187182\n",
      "PctWOFullPlumb \t 270.39352827129903\n",
      "MedRentPctHousInc \t 187.55669519607846\n",
      "NumInShelters \t 279.0266506368465\n",
      "NumStreet \t 218.8042206900394\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Com_x.columns.values)):\n",
    "    if fs.get_support()[i]:\n",
    "        print (Com_x.columns.values[i],'\\t', fs.scores_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Next, perform Ridge Regression and Lasso Regression using the modules from sklearn.linear_model. In each case, perform systematic model selection to identify the optimal alpha parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso \n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x_var, y_var, test_size=0.2, random_state = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematic Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is modified from the original function calc_params in Lec 6 example notebook\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "def best_params(x_var, y_var, clfModel, param_name, param_values, K):\n",
    "    \n",
    "    # Convert x, y input to Numpy arrays\n",
    "    x_var = np.array(x_var)\n",
    "    y_var = np.array(y_var)\n",
    "\n",
    "    # Set training and testing scores to 0\n",
    "    train_scores = np.zeros(len(param_values))\n",
    "    test_scores = np.zeros(len(param_values))\n",
    "    train_scores_RMSE = np.zeros(len(param_values))\n",
    "    test_scores_RMSE= np.zeros(len(param_values))\n",
    "    # iterate over parameter values\n",
    "    print (\"parameter  parameter value    MAE Score(Train)     MAE Score(Test)         RMSE(Train)      RMSE(Test)\")\n",
    "    for i, param_value in enumerate(param_values):\n",
    "        \n",
    "        # set classifier parameters\n",
    "        clfModel.set_params(**{param_name:param_value})\n",
    "        \n",
    "        # initialize the K scores obtained for each fold\n",
    "        k_train_scores = np.zeros(K)\n",
    "        k_test_scores = np.zeros(K)\n",
    "        k_train_RMSE = np.zeros(K)\n",
    "        k_test_RMSE = np.zeros(K)\n",
    "        # create KFold cross validation\n",
    "        cv = KFold(K, shuffle=True, random_state=0)\n",
    "        \n",
    "        # iterate over the K folds\n",
    "        for j, (train, test) in enumerate(cv.split(x_var)):\n",
    "            # fit the classifier in the corresponding fold\n",
    "            # and obtain the corresponding accuracy scores on train and test sets\n",
    "            clfModel.fit([x_var[k] for k in train], y_var[train])\n",
    "            pred_train = clfModel.predict(x_var[train])\n",
    "            pred_test = clfModel.predict(x_var[test])   \n",
    "            k_train_scores[j] = mean_absolute_error(y_var[train], pred_train)\n",
    "            k_test_scores[j] = mean_absolute_error(y_var[test], pred_test)\n",
    "            k_train_RMSE[j] = sqrt(mean_squared_error(y_var[train], pred_train))\n",
    "            k_test_RMSE[j] = sqrt(mean_squared_error(y_var[test], pred_test))\n",
    "                      \n",
    "        # store the mean of the K fold scores\n",
    "        train_scores[i] = np.mean(k_train_scores)\n",
    "        test_scores[i] = np.mean(k_test_scores)\n",
    "        train_scores_RMSE[i] = np.mean(k_train_RMSE)\n",
    "        test_scores_RMSE[i] = np.mean(k_test_RMSE)\n",
    "        print (\"%s: %18.5f  %18.5f  %18.5f  %18.5f  %18.5f\"  %(param_name, param_value,train_scores[i], test_scores[i], train_scores_RMSE[i],test_scores_RMSE[i]))\n",
    "  \n",
    "    #plot the training and testing scores in a log scale\n",
    "    plt.plot(param_values, train_scores, label='Train', alpha=0.4, lw=2, c='b')\n",
    "    plt.plot(param_values, test_scores, label='X Val', alpha=0.4, lw=2, c='g')\n",
    "    plt.legend(loc=7)\n",
    "    plt.xlabel(param_name + \" values\")\n",
    "    plt.ylabel(\"Mean Absoute Error\")\n",
    "\n",
    "    #return the training and testing scores on each parameter value\n",
    "    return train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the alpha input and model input for passing the function above\n",
    "alphaparameter = np.linspace(0.0001, 20, 20)\n",
    "alphaparameter = np.array([float(a) for a in alphaparameter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter  parameter value    MAE Score(Train)     MAE Score(Test)         RMSE(Train)      RMSE(Test)\n",
      "alpha:            0.00010             0.08812             0.09613             0.12434             0.13481\n",
      "alpha:            1.05273             0.08828             0.09374             0.12593             0.13350\n",
      "alpha:            2.10535             0.08859             0.09325             0.12680             0.13350\n",
      "alpha:            3.15798             0.08890             0.09307             0.12744             0.13356\n",
      "alpha:            4.21061             0.08916             0.09296             0.12793             0.13363\n",
      "alpha:            5.26323             0.08937             0.09292             0.12834             0.13369\n",
      "alpha:            6.31586             0.08956             0.09293             0.12868             0.13374\n",
      "alpha:            7.36848             0.08973             0.09295             0.12898             0.13380\n",
      "alpha:            8.42111             0.08988             0.09298             0.12924             0.13385\n",
      "alpha:            9.47374             0.09002             0.09301             0.12947             0.13390\n",
      "alpha:           10.52636             0.09015             0.09303             0.12969             0.13395\n",
      "alpha:           11.57899             0.09028             0.09306             0.12988             0.13400\n",
      "alpha:           12.63162             0.09039             0.09309             0.13006             0.13405\n",
      "alpha:           13.68424             0.09050             0.09312             0.13022             0.13409\n",
      "alpha:           14.73687             0.09060             0.09314             0.13038             0.13414\n",
      "alpha:           15.78949             0.09069             0.09317             0.13053             0.13419\n",
      "alpha:           16.84212             0.09079             0.09320             0.13067             0.13423\n",
      "alpha:           17.89475             0.09088             0.09324             0.13080             0.13428\n",
      "alpha:           18.94737             0.09096             0.09327             0.13092             0.13432\n",
      "alpha:           20.00000             0.09104             0.09330             0.13104             0.13437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09,\n",
       "        0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09]),\n",
       " array([0.1 , 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09,\n",
       "        0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_model = Ridge()\n",
    "best_params(X_train, Y_train, ridge_model, \"alpha\", alphaparameter, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best alpha for train and test set would be 3.15798 with the lowest MAE score and RMSE score.\n",
    "#### So, we will fit the Ridge regrssion model with the alpha = 3.15798."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression\n",
      "Mean absolute error on test data: 0.10164740\n",
      "RMSE error on test data: 0.14658250\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(fit_intercept=True, alpha=3.15798)\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "pred_Y = ridge_model.predict(X_test)\n",
    "err = pred_Y-Y_test\n",
    "total_error = np.dot(err,err)\n",
    "RMSEScore_Rid = np.sqrt(total_error/len(pred_Y))\n",
    "MAEScore_Rid = mean_absolute_error(Y_test, pred_Y)\n",
    "print(\"Ridge Regression\")\n",
    "print('Mean absolute error on test data: %0.8f' % MAEScore_Rid)\n",
    "print('RMSE error on test data: %0.8f' % RMSEScore_Rid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter  parameter value    MAE Score(Train)     MAE Score(Test)         RMSE(Train)      RMSE(Test)\n",
      "alpha:            0.00010             0.08798             0.09482             0.12464             0.13387\n",
      "alpha:            1.05273             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:            2.10535             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:            3.15798             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:            4.21061             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:            5.26323             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:            6.31586             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:            7.36848             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:            8.42111             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:            9.47374             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           10.52636             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           11.57899             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           12.63162             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           13.68424             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           14.73687             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           15.78949             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           16.84212             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           17.89475             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           18.94737             0.17177             0.17178             0.22563             0.22551\n",
      "alpha:           20.00000             0.17177             0.17178             0.22563             0.22551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.09, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17,\n",
       "        0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17]),\n",
       " array([0.09, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17,\n",
       "        0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_model = Lasso()\n",
    "best_params(X_train, Y_train,lasso_model, \"alpha\", alphaparameter, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the graph and table above, the MAE and RMSE scores are relatively constant as the alpha value increases beyond 1.05.\n",
    "#### The best alpha for train and test set would be 0.0001 with the lowest MAE score and RMSE score.\n",
    "#### So, we will fit the Lasso regrssion model with the alpha = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression\n",
      "Mean absolute error on test data: 0.10179228\n",
      "RMSE error on test data: 0.14685379\n"
     ]
    }
   ],
   "source": [
    "Lasso_model = Lasso(fit_intercept=True, alpha=0.0001)\n",
    "Lasso_model.fit(X_train, Y_train)\n",
    "pred_Y = Lasso_model.predict(X_test)\n",
    "err = pred_Y-Y_test\n",
    "total_error = np.dot(err,err)\n",
    "RMSEScore_Las = np.sqrt(total_error/len(pred_Y))\n",
    "MAEScore_Las = mean_absolute_error(Y_test, pred_Y)\n",
    "print (\"Lasso Regression\")\n",
    "print('Mean absolute error on test data: %0.8f' % MAEScore_Las)\n",
    "print('RMSE error on test data: %0.8f' % RMSEScore_Las)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing between 2 models, the Ridge Regression model performs slightly better as both its MAE and RMSE scores are lower than those of Lasso Model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression\n",
    "- For Ridge regression, the best alpha is equal to 3.15874, which has the lowest MAE score of 0.09307(Test).\n",
    "- From the graph above, the MAE score of test set increases as the alpha value increases.\n",
    "- Fitting model with 20% of data (test set), our Ridge model has the MAE of 0.1016 and the RMSE of 0.1465.\n",
    "- Both RMSE and MAE indicates how well of our model can explain the overall data, the the lower error is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression\n",
    "- For Lasso regression, the best alpha is equal to 0.0001, which has the lowest MAE score of 0.09319(Test).\n",
    "- From the graph above, the MAE score of test set increases significantly from alpha value = 0.0001 to 1.\n",
    "- Then the MASE score stays constant beyond alpha = 1 to 20.\n",
    "- Fitting model with 20% of data (test set), our Lasso model has the MAE of 0.1017 and the RMSE of 0.1468.\n",
    "- Both RMSE and MAE indicates how well of our model can explain the overall data, the the lower error is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e.Next, perform regression using Stochastic Gradient Descent for regression. For this part, you should use the SGDRegessor module from sklearn.linear_model. Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = np.array(Com_x)\n",
    "y_var = np.array(Com_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data: 20% test and 80% train\n",
    "### Standarize scale and perform GridSearch ( k=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'penalty': 'l2'}\n",
      "0.63703450223723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_var)\n",
    "x_s = scaler.transform(x_var)\n",
    "#Split data to 20% test 80% train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_s, y_var, test_size=0.2, random_state = 50)\n",
    "\n",
    "sgdreg = SGDRegressor()\n",
    "GridSerach = GridSearchCV(sgdreg,{'penalty': ['l2','l1'],'alpha': np.linspace(0.0001, 10, 100)}, cv=5, verbose=0)\n",
    "GridSerach.fit(X_train, Y_train)\n",
    "print(GridSerach.best_params_)\n",
    "print(GridSerach.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the GridSearch, the best parmeter is 'penalty': 'l2' and 'alpha': 0.0001\n",
    "### We will use these parameter in the SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Stochastic Gradient Descent Regression\n",
      "RMSE on train: 0.125977\n",
      "RMSE on test:  0.145399\n",
      "MAE on train:  0.088846\n",
      "MAE on test:   0.101156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, SGDRegressor \n",
    "\n",
    "sgdreg=SGDRegressor(penalty='l2', alpha=0.0001, n_iter=200)\n",
    "# Calculate the RMSE for fitting a single model\n",
    "#For train model\n",
    "sgdreg.fit(X_train,Y_train)\n",
    "p_train = sgdreg.predict(X_train)\n",
    "err_train = p_train-Y_train\n",
    "total_error_train = np.dot(err_train,err_train)\n",
    "rmse_train = np.sqrt(total_error_train/len(p_train))\n",
    "MAE_train = mean_absolute_error(Y_train, p_train)\n",
    "\n",
    "#For test model\n",
    "sgdreg.fit(X_train,Y_train)\n",
    "p_test = sgdreg.predict(X_test)\n",
    "e_test = p_test-Y_test\n",
    "xval_err_test = np.dot(e_test,e_test)\n",
    "rmse_test = np.sqrt(xval_err_test/len(p_test))\n",
    "MAE_test = mean_absolute_error(Y_test, p_test)\n",
    "\n",
    "method_name = 'Stochastic Gradient Descent Regression'\n",
    "print('Method: %s' %method_name)  \n",
    "print('RMSE on train: %f' %rmse_train)\n",
    "print('RMSE on test:  %f' %rmse_test)  \n",
    "print('MAE on train:  %f' %MAE_train)\n",
    "print('MAE on test:   %f' %MAE_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter  parameter value    MAE Score(Train)     MAE Score(Test)         RMSE(Train)      RMSE(Test)\n",
      "l1_ratio:            0.00000             0.09435             0.09767             0.13264             0.13762\n",
      "l1_ratio:            0.05263             0.09295             0.09697             0.13150             0.13792\n",
      "l1_ratio:            0.10526             0.09303             0.09831             0.13068             0.13811\n",
      "l1_ratio:            0.15789             0.09345             0.09758             0.13155             0.13731\n",
      "l1_ratio:            0.21053             0.09265             0.09835             0.13105             0.13844\n",
      "l1_ratio:            0.26316             0.09262             0.09766             0.13041             0.13722\n",
      "l1_ratio:            0.31579             0.09102             0.09450             0.12988             0.13550\n",
      "l1_ratio:            0.36842             0.09356             0.09767             0.13134             0.13827\n",
      "l1_ratio:            0.42105             0.09284             0.09539             0.13123             0.13564\n",
      "l1_ratio:            0.47368             0.09211             0.09533             0.13033             0.13514\n",
      "l1_ratio:            0.52632             0.09224             0.09589             0.13061             0.13552\n",
      "l1_ratio:            0.57895             0.09249             0.09645             0.13063             0.13508\n",
      "l1_ratio:            0.63158             0.09217             0.09671             0.13068             0.13743\n",
      "l1_ratio:            0.68421             0.09333             0.09759             0.13211             0.13851\n",
      "l1_ratio:            0.73684             0.09217             0.09713             0.13087             0.13755\n",
      "l1_ratio:            0.78947             0.09209             0.09590             0.12971             0.13556\n",
      "l1_ratio:            0.84211             0.09176             0.09815             0.13076             0.13924\n",
      "l1_ratio:            0.89474             0.09072             0.09529             0.12908             0.13522\n",
      "l1_ratio:            0.94737             0.09262             0.09812             0.13135             0.13954\n",
      "l1_ratio:            1.00000             0.09286             0.09887             0.13116             0.13895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09,\n",
       "        0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09]),\n",
       " array([0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.09, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l1_parameter = np.linspace(0.0,1.0, 20)\n",
    "l1_parameter = np.array([float(l) for l in l1_parameter])\n",
    "sgd = SGDRegressor(penalty='elasticnet')\n",
    "best_params(X_train, Y_train, sgd, \"l1_ratio\" ,l1_parameter, 5)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the graph above, the MAE score of train and test is relatively volatile as the l1_ratio value increases. The best l1_ratio for test set would be 0.57895 with the lowest MAE and RMSE for test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting model with the best l1_ratio = 0.89474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Regression\n",
      "Mean absolute error on test data: 0.10499476\n",
      "RMSE error on test data: 0.15328173\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDRegressor(penalty='elasticnet', l1_ratio=0.89474)\n",
    "sgd_model.fit(X_train, Y_train)\n",
    "pred_Y = sgd_model.predict(X_test)\n",
    "err = pred_Y-Y_test\n",
    "total_error = np.dot(err,err)\n",
    "RMSEScore_sgd = np.sqrt(total_error/len(pred_Y))\n",
    "MAEScore_sgd = mean_absolute_error(Y_test, pred_Y)\n",
    "print (\"SGD Regression\")\n",
    "print('Mean absolute error on test data: %0.8f' % MAEScore_sgd)\n",
    "print('RMSE error on test data: %0.8f' % RMSEScore_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Part b. : Standard Linear Regression\n",
    "- The RMSE from full training data is 0.128890\n",
    "- The RMSE from 10 K-folds is 0.135861"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Part d. : Ridge Regression\n",
    "- Mean absolute error on test data: 0.101647\n",
    "- RMSE error on test data (20%): 0.1465825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Part d. : Lasso Regression\n",
    "- Mean absolute error on test data: 0.1017922\n",
    "- RMSE error on test data (20%): 0.14685379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Part e. : SGDRegessor\n",
    "- RMSE on train: 0.125977 (GridSearch)\n",
    "- RMSE on test: 0.145399 (GridSearch)\n",
    "- RMSE error on test data (20%): 0.14899100 (model selection l1_ratio = 0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models performs relatively well and in a similar fashion, which the RMSE from SGD regressor is slightly higher than that of Lasso and Ridge Regression. From the GridSearch, the best ratio {'penalty': 'l2', 'alpha': 0.0001} From the graph above, the MAE score of train and test is relatively volatile as the l1_ratio value increases. The best l1_ratio for train and test set would be 0.895 with the lowest MAE. From the model selection (l1_ratio = 0.895), The RMSE score is 0.148991 comparing to other models, this model has the highest RMSE score, so it relatively underperforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 Automatic Document Clustering [ Dataset : newsgroups5.zip ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Amy\\\\Desktop\\\\dsc478\\\\newsgroups5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Create your own distance function that, instead of using Euclidean distance, uses Cosine similarity. This is the distance function you will use to pass to the kMeans function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- We will use kMeans and Random_centroid functions from Ch 10 in part C\n",
    "- So, D and x is are array inputs from Kmeans function in part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cos_Sim(x,D):# where D and x is are array inputs from Kmeans function in part C\n",
    "    \n",
    "    normX = np.linalg.norm(x)\n",
    "    normD = np.linalg.norm(D)\n",
    "    CosSim = np.dot(D,x)/(normD * normX )\n",
    "    dist = 1 - CosSim\n",
    "    return dist\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Load the data set [Note: the data matrix provided has terms as rows and documents as columns. Since you will be clustering documents, you'll need to take the transpose of this matrix so that your main data matrix is a document x term matrix. In Numpy, you may use the \".T\" operation to obtain the transpose.] Then, split the data set (the document x term matrix) and set aside 20% for later use (see below). Use the 80% segment for clustering in the next part. The 20% portion must be a random subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docs= np.loadtxt(\"matrix.txt\",dtype=int, delimiter=',')\n",
    "Docs_DT = pd.DataFrame(Docs.T)\n",
    "Classes = np.loadtxt(\"classes.txt\", dtype=int, delimiter=' ',skiprows=1)\n",
    "Classes_DF = pd.DataFrame(Classes)\n",
    "Classes_DF = Classes_DF.drop(Classes_DF.columns[0], axis=1)\n",
    "Label = np.loadtxt(\"terms.txt\", dtype=str, delimiter='\\t')\n",
    "Label_DF = np.array(pd.DataFrame(Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9318</th>\n",
       "      <th>9319</th>\n",
       "      <th>9320</th>\n",
       "      <th>9321</th>\n",
       "      <th>9322</th>\n",
       "      <th>9323</th>\n",
       "      <th>9324</th>\n",
       "      <th>9325</th>\n",
       "      <th>9326</th>\n",
       "      <th>9327</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   9318  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "1     0     0     0     0     0     0     0     0     0     1  ...      0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   9319  9320  9321  9322  9323  9324  9325  9326  9327  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 9328 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Docs_DT.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1\n",
       "0  0\n",
       "1  1\n",
       "2  1\n",
       "3  1\n",
       "4  2"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classes_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['aa'],\n",
       "       ['aargh'],\n",
       "       ['aaron'],\n",
       "       ...,\n",
       "       ['zw'],\n",
       "       ['zx'],\n",
       "       ['zz']], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into 20% test and 80% train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 9328)\n",
      "(500, 9328)\n",
      "(2000, 1)\n",
      "(500, 1)\n"
     ]
    }
   ],
   "source": [
    " #Split data into 20% test, 80% train\n",
    "from sklearn.model_selection import train_test_split\n",
    "Docs_train_DT, Docs_test_DT, Classes_train, Classes_test = train_test_split(Docs_DT, Classes_DF, test_size=0.2, random_state=50)\n",
    "print (Docs_train_DT.shape)\n",
    "print (Docs_test_DT.shape)\n",
    "print (Classes_train.shape)\n",
    "print (Classes_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Perform Kmeans clustering on the training data. Write a function to display the top N terms in each cluster along with the cluster DF values for each term and the size of the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.8  7.8  7.8  ... 7.8  7.8  7.8 ]\n",
      " [9.38 9.38 9.38 ... 9.38 9.38 9.38]\n",
      " [6.72 6.72 6.72 ... 6.72 6.72 6.72]\n",
      " ...\n",
      " [9.38 9.38 9.38 ... 9.38 9.38 9.38]\n",
      " [5.76 5.76 5.76 ... 5.76 5.76 5.76]\n",
      " [3.8  3.8  3.8  ... 3.8  3.8  3.8 ]]\n"
     ]
    }
   ],
   "source": [
    "Docs_DT = Docs_train_DT\n",
    "Docs_TD = Docs_DT.T\n",
    "Docs_DT_test = Docs_test_DT\n",
    "Docs_TD_test = Docs_DT_test.T\n",
    "\n",
    "numTerms= Docs_TD.shape[0]\n",
    "NDocs = Docs_TD.shape[1]\n",
    "termFreqs = Docs_train_DT.sum(axis=1) \n",
    "DF_Train = np.array([(Docs_TD!=0).sum(1)]).T\n",
    "\n",
    "# Create a matrix with all entries = NDocs\n",
    "NMatrix = np.ones(np.shape(Docs_TD), dtype=float)*NDocs\n",
    "#Find IDF\n",
    "IDF = np.log2(np.divide(NMatrix, DF_Train))\n",
    "print (IDF[0:10,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "- We need to perform TFxIDF normalization on the training set seperately and then use the IDF-vector from the training set to calculate the TF-IDF vectors of the test set. Test set is small and has the purpose for testing the model not testing the IDF performance, so we shouldn't do TFxIDF sepeartely for the test set\n",
    "- We will replace the small value, large value, and NaN of IDF metric with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFxIDF Train set \n",
      "          SHAPE  :  (2000, 9328)\n",
      "          MIN    :  0.0\n",
      "TFxIDF Test set \n",
      "          SHAPE  :  (500, 9328)\n",
      "          MIN    :  0.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import inf, isnan\n",
    "\n",
    "#Train set (80% = 2000 values)\n",
    "tdTFxIDF_train = np.array(Docs_TD * IDF)\n",
    "dtTFxIDF_train = tdTFxIDF_train.T\n",
    "dtTFxIDF_train[np.isnan(dtTFxIDF_train)] = 0\n",
    "dtTFxIDF_train[dtTFxIDF_train == inf] = 0\n",
    "dtTFxIDF_train[dtTFxIDF_train == -inf] = 0\n",
    "print (\"TFxIDF Train set \")\n",
    "print (\"          SHAPE  : \", dtTFxIDF_train.shape)\n",
    "print (\"          MIN    : \",dtTFxIDF_train.min())\n",
    "\n",
    "#Test set (20% = 5000 values)\n",
    "tdTFxIDF_test = np.array(Docs_TD_test * IDF[:,:500])\n",
    "dtTFxIDF_test = tdTFxIDF_test.T\n",
    "dtTFxIDF_test[np.isnan(dtTFxIDF_test)] = 0\n",
    "dtTFxIDF_test[dtTFxIDF_test == inf] = 0\n",
    "dtTFxIDF_test[dtTFxIDF_test == -inf] = 0\n",
    "print (\"TFxIDF Test set \")\n",
    "print (\"          SHAPE  : \", dtTFxIDF_test.shape)\n",
    "print (\"          MIN    : \", dtTFxIDF_test.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = blue>Notes:</font>\n",
    "##### <font color = blue>We will use the metric \"dtTFxIDF_train\" for clustering</font>\n",
    "##### <font color = blue>The following functions randCent and kMeans are from the ML book Ch. 10 kMeans.py</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red>The imported module from kMeans.py doesn't work, because  I use different version of Python</font>\n",
    "### <font color = red>so, I copied and pasted the functions to this notebook.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kMeans.py doesn't work, so copy the whole codes\n",
    "#import kMeans as kmeans\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create centroids function modified from (Ch 10)\n",
    "def randCent(dataSet, k):\n",
    "    n = shape(dataSet)[1]\n",
    "    centroids = zeros((k,n), dtype=float)\n",
    "    for j in range(n): #create random cluster centers\n",
    "        minJ = min(dataSet[:,j])\n",
    "        rangeJ = float(max(dataSet[:,j]) - minJ)\n",
    "        centroids[:,j] = minJ + rangeJ * random.rand(k)\n",
    "    return centroids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.98,  2.46, 23.21, ..., 18.5 , 34.34, 17.6 ],\n",
       "       [ 0.2 ,  4.74, 12.13, ..., 33.58, 20.06,  7.36]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test function with k = 2 centroids\n",
    "randCent(dtTFxIDF_train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(dataSet, k, distMeas=Cos_Sim, createCent=randCent):\n",
    "    m = shape(dataSet)[0]\n",
    "    clusterAssment = zeros((m,2))#create mat to assign data points \n",
    "                                      #to a centroid, also holds SE of each point\n",
    "    centroids = createCent(dataSet, k)\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        for i in range(m):#for each data point assign it to the closest centroid\n",
    "            minDist = inf; minIndex = -1\n",
    "            for j in range(k):\n",
    "                distJI = distMeas(centroids[j,:],dataSet[i,:])\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI; minIndex = j\n",
    "            if clusterAssment[i,0] != minIndex: clusterChanged = True\n",
    "            clusterAssment[i,:] = minIndex,minDist**2\n",
    "        # print centroids\n",
    "        for cent in range(k):#recalculate centroids\n",
    "            ptsInClust = dataSet[nonzero(clusterAssment[:,0]==cent)[0]] #get all the point in this cluster - Note: this was incorrect in the original distribution.\n",
    "            if(len(ptsInClust)!=0):\n",
    "                centroids[cent,:] = mean(ptsInClust, axis=0) #assign centroid to mean - Note condition was added 10/28/2013\n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The findTerms function prints top N terms with high frequency in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Function returns the top N term of each cluster\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "def findTerms(Data, k, N):\n",
    "    #MatData = np.mat(Data)\n",
    "    myCentroids, clustAssing = kMeans(Data,k)\n",
    "    for i in range(0,k,1):\n",
    "        print(\"CLUSTER: %d   results\" %(i))\n",
    "        clusterNum = clustAssing[:,0]#Clustering Number\n",
    "        clusterDT = Data[clusterNum == i]#Create Matrix for each cluster (DT)\n",
    "        numDocs =  clusterDT.shape[0]#add row of each cluster Matrix\n",
    "        print (\"Number of documents in cluster : %8d   \" %(numDocs))\n",
    "        DocsFreq = np.array([(clusterDT.T!=0).sum(1)]).T\n",
    "        freqPercent = DocsFreq/float(numDocs)\n",
    "        Results = np.concatenate((Label_DF, DocsFreq, freqPercent), axis=1)#each element = [percentFreq, freq, term]\n",
    "        sortedResults = np.flip(Results[Results[:,-1].argsort()])#Sorted by decesending order\n",
    "        print (\"        Word      DF    PercentofDocs\")\n",
    "        for i, result in enumerate(sortedResults[:N]):\n",
    "            term = result[2]\n",
    "            DF = result[1]\n",
    "            freqPer = (result[0]*100)\n",
    "            print (\"%12s   %5d   %14.6f  \"  %(term, DF , freqPer)) \n",
    "        print (\"-----------------------------------------------------\")\n",
    "    return myCentroids, clustAssing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER: 0   results\n",
      "Number of documents in cluster :      811   \n",
      "        Word      DF    PercentofDocs\n",
      "       write     476        58.692972  \n",
      "          on     380        46.855734  \n",
      "      articl     353        43.526510  \n",
      "        know     291        35.881628  \n",
      "       think     287        35.388409  \n",
      "        just     272        33.538841  \n",
      "          go     270        33.292232  \n",
      "        time     251        30.949445  \n",
      "         see     250        30.826141  \n",
      "       peopl     249        30.702836  \n",
      "-----------------------------------------------------\n",
      "CLUSTER: 1   results\n",
      "Number of documents in cluster :      770   \n",
      "        Word      DF    PercentofDocs\n",
      "      window     290        37.662338  \n",
      "        sale     232        30.129870  \n",
      "       thank     219        28.441558  \n",
      "       pleas     218        28.311688  \n",
      "       email     214        27.792208  \n",
      "       write     210        27.272727  \n",
      "          on     206        26.753247  \n",
      "         get     198        25.714286  \n",
      "        work     181        23.506494  \n",
      "        know     167        21.688312  \n",
      "-----------------------------------------------------\n",
      "CLUSTER: 2   results\n",
      "Number of documents in cluster :      403   \n",
      "        Word      DF    PercentofDocs\n",
      "       write     264        65.508685  \n",
      "      articl     202        50.124069  \n",
      "     clipper     199        49.379653  \n",
      "         kei     191        47.394541  \n",
      "     encrypt     184        45.657568  \n",
      "          on     169        41.935484  \n",
      "        chip     161        39.950372  \n",
      "         get     142        35.235732  \n",
      "      govern     139        34.491315  \n",
      "        just     134        33.250620  \n",
      "-----------------------------------------------------\n",
      "CLUSTER: 3   results\n",
      "Number of documents in cluster :       12   \n",
      "        Word      DF    PercentofDocs\n",
      "          mq       8        66.666667  \n",
      "          ws       8        66.666667  \n",
      "          mx       8        66.666667  \n",
      "          cd       8        66.666667  \n",
      "          mo       8        66.666667  \n",
      "          gm       8        66.666667  \n",
      "          mm       8        66.666667  \n",
      "          mi       8        66.666667  \n",
      "          ma       8        66.666667  \n",
      "          ng       8        66.666667  \n",
      "-----------------------------------------------------\n",
      "CLUSTER: 4   results\n",
      "Number of documents in cluster :        4   \n",
      "        Word      DF    PercentofDocs\n",
      "          ax       4       100.000000  \n",
      "        bhjn       3        75.000000  \n",
      "         zbj       3        75.000000  \n",
      "         bwm       3        75.000000  \n",
      "      wwizkn       3        75.000000  \n",
      "        wwiz       3        75.000000  \n",
      "salmonusdedu       3        75.000000  \n",
      "          mi       3        75.000000  \n",
      "          wm       3        75.000000  \n",
      "         giz       3        75.000000  \n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "centroids, clustAssing = findTerms(dtTFxIDF_train, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Using the cluster assignments from Kmeans clustering, compare your 5 clusters to the 5 pre-assigned classes by computing the Completeness and Homogeneity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2316</th>\n",
       "      <th>2146</th>\n",
       "      <th>398</th>\n",
       "      <th>215</th>\n",
       "      <th>1730</th>\n",
       "      <th>1662</th>\n",
       "      <th>912</th>\n",
       "      <th>1019</th>\n",
       "      <th>374</th>\n",
       "      <th>1070</th>\n",
       "      <th>...</th>\n",
       "      <th>2143</th>\n",
       "      <th>70</th>\n",
       "      <th>2277</th>\n",
       "      <th>2118</th>\n",
       "      <th>132</th>\n",
       "      <th>2014</th>\n",
       "      <th>2157</th>\n",
       "      <th>1931</th>\n",
       "      <th>1504</th>\n",
       "      <th>1712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2316  2146  398   215   1730  1662  912   1019  374   1070  ...   2143  \\\n",
       "1     2     4     0     1     4     0     2     1     4     4  ...      2   \n",
       "\n",
       "   70    2277  2118  132   2014  2157  1931  1504  1712  \n",
       "1     4     2     3     0     4     1     0     4     0  \n",
       "\n",
       "[1 rows x 2000 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classes_train_T = Classes_train.T\n",
    "Classes_train_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, ..., 0, 4, 0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classes_train_T = np.array(Classes_train_T)[0]\n",
    "Classes_train_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterResults = clustAssing[:,0].astype(int) \n",
    "clusterResults "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The completeness of 5 Clusters :  0.79187061\n",
      "The homogeneity of  5 Clusters :  0.54095119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "\n",
    "completeScore = completeness_score(Classes_train_T,clusterResults)\n",
    "homoScore = homogeneity_score(Classes_train_T,clusterResults)\n",
    "\n",
    "print ('The completeness of 5 Clusters :  %.8f' %completeScore)\n",
    "print ('The homogeneity of  5 Clusters :  %.8f' %homoScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "- The completeness of 0.79187 is relative high, implying that majority samples of a single given class are assigned to the same cluster.\n",
    "- The homogeneity score of 0.5409 is moderately high, indicating that samples of a single class belong to a single cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Finally, using your cluster assignments as class labels, categorize each of the documents in the 20% set-aside data into each of the appropriate cluster. Your categorization should be based on Cosine similarity between each test document and cluster centroids. For each test document show the predicted class label as well as Cosine similarity to the corresponding cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03,  0.03,  0.22, ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.04,  0.  ,  0.05, ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 5.2 ,  0.  ,  0.  , ...,  8.3 ,  4.69, 11.21],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtTFxIDF_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes: I wrote 2 new functions. \n",
    "####           1. Cos_Similarity( ) that take 2 array inputs and return Cosine Similarity (not distance)\n",
    "####           2. predict_Cluster( ) that take 2 array inputs and print Cosine Similarity and predicted clusture of each test doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cos_Similarity(x,D):#return Cosine Similarity not Distance  \n",
    "    normX = np.linalg.norm(x)\n",
    "    normD = np.linalg.norm(D)\n",
    "    CosSim = np.dot(D,x)/(normD * normX )\n",
    "    return CosSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Cluster(data, centroids, Measuredist=Cos_Similarity):\n",
    "    print (\" Index Doc.  Cluster 0   Cluster 1   Cluster 2   Cluster 3   Cluster 4    Predicted Class\")\n",
    "    index = 0\n",
    "    for row in data:#iterate each documents\n",
    "        cluster = 0 #0,1,2,3,4\n",
    "        cosSim = []\n",
    "        for centinCluster in centroids:\n",
    "            CosSimValue = Measuredist(row, centinCluster)\n",
    "            cosSim.append(CosSimValue)\n",
    "        pred_cluster = cosSim.index(max(cosSim))\n",
    "        print (\"%10d %11.5f %11.5f %11.5f %11.5f %11.5f %10d \" %(index, cosSim[0],cosSim[1],cosSim[2],cosSim[3],cosSim[4], pred_cluster))\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted 5 Clusters based on Cosine Similarity     --->  ( Cluster#  0, 1, 2, 3, 4 )\n",
    "#### where row = docs, columns = Cosine Similarity in each cluster\n",
    "#### 5 Clusters ranges from: 0, 1, 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Index Doc.  Cluster 0   Cluster 1   Cluster 2   Cluster 3   Cluster 4    Predicted Class\n",
      "         0     0.19638     0.05548     0.04851     0.00460     0.00002          0 \n",
      "         1     0.20175     0.05433     0.06399     0.00283     0.00000          0 \n",
      "         2     0.07082     0.07550     0.11795     0.01059     0.00000          2 \n",
      "         3     0.02718     0.11395     0.03003     0.00265     0.00001          1 \n",
      "         4     0.12314     0.05226     0.05014     0.01283     0.00002          0 \n",
      "         5     0.15828     0.04837     0.04174     0.00087     0.00000          0 \n",
      "         6     0.04207     0.08218     0.03448     0.00143     0.00000          1 \n",
      "         7     0.13907     0.14743     0.30194     0.00506     0.00001          2 \n",
      "         8     0.13422     0.04198     0.06953     0.00115     0.00000          0 \n",
      "         9     0.05048     0.11441     0.04102     0.00402     0.00000          1 \n",
      "        10     0.11040     0.09275     0.29547     0.00441     0.00001          2 \n",
      "        11     0.06656     0.06915     0.36803     0.00700     0.00000          2 \n",
      "        12     0.05174     0.20433     0.05404     0.00302     0.00001          1 \n",
      "        13     0.05478     0.09438     0.07084     0.00070     0.00000          1 \n",
      "        14     0.09459     0.08054     0.05622     0.01300     0.00016          0 \n",
      "        15     0.09624     0.09973     0.38207     0.00261     0.00000          2 \n",
      "        16     0.09623     0.07800     0.17068     0.00254     0.00000          2 \n",
      "        17     0.03934     0.13659     0.04931     0.00418     0.00004          1 \n",
      "        18     0.04804     0.06605     0.04224     0.00432     0.00001          1 \n",
      "        19     0.06928     0.04751     0.11439     0.00956     0.00001          2 \n",
      "        20     0.03788     0.08072     0.06065     0.00044     0.00000          1 \n",
      "        21     0.29226     0.10656     0.10607     0.00166     0.00000          0 \n",
      "        22     0.04630     0.14122     0.11735     0.01133     0.00003          1 \n",
      "        23     0.02192     0.07378     0.02610     0.00149     0.00000          1 \n",
      "        24     0.02602     0.08910     0.03651     0.00336     0.00005          1 \n",
      "        25     0.06133     0.24466     0.07751     0.00649     0.00001          1 \n",
      "        26     0.05225     0.25955     0.07040     0.00599     0.00000          1 \n",
      "        27     0.05708     0.05467     0.21912     0.00137     0.00000          2 \n",
      "        28     0.08160     0.10084     0.21006     0.00785     0.00000          2 \n",
      "        29     0.02315     0.05868     0.01806     0.00033     0.00001          1 \n",
      "        30     0.03857     0.06470     0.02794     0.02707     0.00028          1 \n",
      "        31     0.05036     0.20363     0.06435     0.00272     0.00000          1 \n",
      "        32     0.10704     0.03061     0.02509     0.04455     0.00002          0 \n",
      "        33     0.05410     0.11388     0.05997     0.00602     0.00002          1 \n",
      "        34     0.17441     0.09619     0.13060     0.00212     0.00000          0 \n",
      "        35     0.07244     0.05719     0.15657     0.01014     0.00001          2 \n",
      "        36     0.11429     0.04016     0.04344     0.00266     0.00000          0 \n",
      "        37     0.16183     0.04231     0.06283     0.01093     0.00002          0 \n",
      "        38     0.07497     0.10747     0.08816     0.00664     0.00005          1 \n",
      "        39     0.13363     0.03736     0.08661     0.00178     0.00000          0 \n",
      "        40     0.12269     0.03861     0.04583     0.00274     0.00000          0 \n",
      "        41     0.00102     0.00173     0.00030     0.03560     0.99981          4 \n",
      "        42     0.06372     0.07755     0.19183     0.00196     0.00001          2 \n",
      "        43     0.03729     0.09159     0.03146     0.02838     0.00012          1 \n",
      "        44     0.02077     0.06056     0.02650     0.00777     0.00006          1 \n",
      "        45     0.07691     0.02384     0.03041     0.00557     0.00000          0 \n",
      "        46     0.11059     0.15222     0.09186     0.00539     0.00001          1 \n",
      "        47     0.08802     0.06142     0.07862     0.00226     0.00000          0 \n",
      "        48     0.18724     0.04264     0.04346     0.00176     0.00001          0 \n",
      "        49     0.03974     0.04269     0.02512     0.00285     0.00000          1 \n",
      "        50     0.10717     0.03010     0.05508     0.00150     0.00000          0 \n",
      "        51     0.06688     0.05833     0.20107     0.00131     0.00000          2 \n",
      "        52     0.23677     0.13645     0.13193     0.00558     0.00003          0 \n",
      "        53     0.35209     0.08507     0.10865     0.00920     0.00003          0 \n",
      "        54     0.14675     0.06916     0.09454     0.00578     0.00015          0 \n",
      "        55     0.03989     0.14457     0.05422     0.00847     0.00001          1 \n",
      "        56     0.13867     0.03481     0.06331     0.00209     0.00001          0 \n",
      "        57     0.01442     0.07384     0.01542     0.01641     0.00000          1 \n",
      "        58     0.22682     0.09598     0.08501     0.02913     0.00001          0 \n",
      "        59     0.02367     0.04242     0.02272     0.00238     0.00000          1 \n",
      "        60     0.22438     0.06776     0.06580     0.00427     0.00002          0 \n",
      "        61     0.14003     0.06065     0.06415     0.00289     0.00000          0 \n",
      "        62     0.09668     0.03592     0.03947     0.00145     0.00000          0 \n",
      "        63     0.10423     0.02901     0.03248     0.01498     0.00001          0 \n",
      "        64     0.09915     0.14058     0.05550     0.00792     0.00006          1 \n",
      "        65     0.06170     0.04344     0.14273     0.01789     0.00019          2 \n",
      "        66     0.02137     0.16810     0.04524     0.00337     0.00001          1 \n",
      "        67     0.05669     0.07692     0.08067     0.00120     0.00000          2 \n",
      "        68     0.06477     0.02643     0.01289     0.00017     0.00002          0 \n",
      "        69     0.04888     0.01370     0.01791     0.00025     0.00000          0 \n",
      "        70     0.04646     0.10187     0.05042     0.00798     0.00000          1 \n",
      "        71     0.07211     0.11850     0.08257     0.00233     0.00001          1 \n",
      "        72     0.13616     0.03018     0.04877     0.00218     0.00000          0 \n",
      "        73     0.27593     0.08175     0.11094     0.00438     0.00000          0 \n",
      "        74     0.03298     0.15260     0.03397     0.00313     0.00000          1 \n",
      "        75     0.02494     0.15852     0.05984     0.00405     0.00001          1 \n",
      "        76     0.18647     0.06189     0.05638     0.00686     0.00005          0 \n",
      "        77     0.08543     0.07020     0.15288     0.00452     0.00002          2 \n",
      "        78     0.07101     0.03322     0.02054     0.00083     0.00000          0 \n",
      "        79     0.00901     0.06133     0.01597     0.00416     0.00001          1 \n",
      "        80     0.14785     0.03081     0.02558     0.00079     0.00006          0 \n",
      "        81     0.08214     0.04796     0.03818     0.00316     0.00000          0 \n",
      "        82     0.18898     0.08437     0.10005     0.00186     0.00001          0 \n",
      "        83     0.16840     0.03813     0.06742     0.00377     0.00000          0 \n",
      "        84     0.04355     0.14342     0.04834     0.00692     0.00000          1 \n",
      "        85     0.04138     0.06988     0.04622     0.00172     0.00001          1 \n",
      "        86     0.02359     0.11850     0.03958     0.00490     0.00000          1 \n",
      "        87     0.27641     0.10200     0.13925     0.00276     0.00002          0 \n",
      "        88     0.03480     0.15154     0.04617     0.00489     0.00000          1 \n",
      "        89     0.26175     0.04833     0.06410     0.00142     0.00001          0 \n",
      "        90     0.01337     0.12671     0.02452     0.00486     0.00030          1 \n",
      "        91     0.08690     0.06550     0.27075     0.00466     0.00000          2 \n",
      "        92     0.10912     0.02146     0.02714     0.00000     0.00000          0 \n",
      "        93     0.12017     0.09172     0.08717     0.00911     0.00002          0 \n",
      "        94     0.09658     0.11422     0.03458     0.00754     0.00006          1 \n",
      "        95     0.16503     0.06414     0.04887     0.01642     0.00017          0 \n",
      "        96     0.09497     0.12382     0.09742     0.00879     0.00000          1 \n",
      "        97     0.08323     0.10081     0.12996     0.00526     0.00000          2 \n",
      "        98     0.08349     0.02970     0.02947     0.00015     0.00000          0 \n",
      "        99     0.10438     0.08401     0.19171     0.00883     0.00000          2 \n",
      "       100     0.15048     0.06714     0.06480     0.00409     0.00001          0 \n",
      "       101     0.18695     0.06395     0.06678     0.00608     0.00001          0 \n",
      "       102     0.02472     0.13605     0.05084     0.00502     0.00000          1 \n",
      "       103     0.02792     0.06695     0.04722     0.00860     0.00001          1 \n",
      "       104     0.05586     0.19131     0.06957     0.00394     0.00002          1 \n",
      "       105     0.02356     0.10207     0.01807     0.00092     0.00000          1 \n",
      "       106     0.11355     0.05086     0.06221     0.00421     0.00000          0 \n",
      "       107     0.10838     0.09827     0.30908     0.00241     0.00001          2 \n",
      "       108     0.00092     0.00148     0.00024     0.03009     0.99994          4 \n",
      "       109     0.04481     0.09590     0.06001     0.00327     0.00001          1 \n",
      "       110     0.02326     0.12788     0.02833     0.00204     0.00003          1 \n",
      "       111     0.05189     0.06921     0.27754     0.00319     0.00000          2 \n",
      "       112     0.19635     0.08815     0.08320     0.00348     0.00000          0 \n",
      "       113     0.07605     0.02503     0.02225     0.00147     0.00000          0 \n",
      "       114     0.17486     0.05887     0.04680     0.00268     0.00001          0 \n",
      "       115     0.06793     0.05618     0.16427     0.01330     0.00004          2 \n",
      "       116     0.01713     0.10635     0.04657     0.00150     0.00000          1 \n",
      "       117     0.09358     0.11956     0.19763     0.00554     0.00001          2 \n",
      "       118     0.08832     0.12895     0.32237     0.01364     0.00010          2 \n",
      "       119     0.07862     0.12586     0.03857     0.00412     0.00032          1 \n",
      "       120     0.11985     0.01728     0.00557     0.00961     0.00001          0 \n",
      "       121     0.11340     0.03245     0.03089     0.00071     0.00000          0 \n",
      "       122     0.07780     0.20758     0.08808     0.02351     0.00000          1 \n",
      "       123     0.07250     0.03909     0.04814     0.01833     0.00004          0 \n",
      "       124     0.03992     0.25773     0.04126     0.00482     0.00001          1 \n",
      "       125     0.11441     0.09114     0.16480     0.00283     0.00000          2 \n",
      "       126     0.08347     0.09467     0.22561     0.00430     0.00001          2 \n",
      "       127     0.23234     0.06229     0.07077     0.00300     0.00001          0 \n",
      "       128     0.13402     0.03890     0.03256     0.00379     0.00004          0 \n",
      "       129     0.05698     0.04942     0.05135     0.00177     0.00000          0 \n",
      "       130     0.05647     0.20990     0.06825     0.00406     0.00001          1 \n",
      "       131     0.12331     0.02868     0.04531     0.00219     0.00000          0 \n",
      "       132     0.05031     0.14415     0.04856     0.00183     0.00001          1 \n",
      "       133     0.06012     0.13534     0.06492     0.00295     0.00001          1 \n",
      "       134     0.10249     0.22245     0.10453     0.00652     0.00000          1 \n",
      "       135     0.04854     0.16821     0.05943     0.01615     0.00005          1 \n",
      "       136     0.17534     0.07530     0.08770     0.00341     0.00000          0 \n",
      "       137     0.02019     0.04994     0.02607     0.00079     0.00000          1 \n",
      "       138     0.05248     0.06494     0.06410     0.01100     0.00000          1 \n",
      "       139     0.02471     0.06796     0.04069     0.00931     0.00003          1 \n",
      "       140     0.06357     0.04352     0.14161     0.00070     0.00000          2 \n",
      "       141     0.12080     0.03679     0.03907     0.00807     0.00003          0 \n",
      "       142     0.18843     0.03622     0.05784     0.00469     0.00001          0 \n",
      "       143     0.03449     0.03297     0.14611     0.00136     0.00001          2 \n",
      "       144     0.10054     0.03747     0.03214     0.00805     0.00022          0 \n",
      "       145     0.05549     0.24182     0.05963     0.00348     0.00001          1 \n",
      "       146     0.11421     0.11835     0.35144     0.00772     0.00003          2 \n",
      "       147     0.07906     0.27873     0.08192     0.00961     0.00042          1 \n",
      "       148     0.04712     0.04771     0.18342     0.00684     0.00002          2 \n",
      "       149     0.06239     0.08850     0.04423     0.01051     0.00001          1 \n",
      "       150     0.03402     0.14668     0.12543     0.00546     0.00000          1 \n",
      "       151     0.11885     0.04790     0.04746     0.00094     0.00001          0 \n",
      "       152     0.06183     0.18740     0.06691     0.00369     0.00002          1 \n",
      "       153     0.21941     0.06916     0.04989     0.00518     0.00003          0 \n",
      "       154     0.05430     0.08099     0.21316     0.00185     0.00000          2 \n",
      "       155     0.04065     0.09068     0.07568     0.00095     0.00000          1 \n",
      "       156     0.05643     0.06436     0.14820     0.00834     0.00000          2 \n",
      "       157     0.05475     0.15703     0.06341     0.00592     0.00001          1 \n",
      "       158     0.01062     0.07801     0.01317     0.00083     0.00002          1 \n",
      "       159     0.13296     0.05504     0.05336     0.00351     0.00000          0 \n",
      "       160     0.07029     0.06805     0.22849     0.00194     0.00000          2 \n",
      "       161     0.04694     0.20994     0.07655     0.00485     0.00001          1 \n",
      "       162     0.10300     0.04686     0.04997     0.00179     0.00001          0 \n",
      "       163     0.06594     0.01727     0.01471     0.10664     0.00009          3 \n",
      "       164     0.03481     0.15820     0.03308     0.00570     0.00001          1 \n",
      "       165     0.06498     0.08340     0.05788     0.00512     0.00004          1 \n",
      "       166     0.02252     0.04560     0.01595     0.00194     0.00000          1 \n",
      "       167     0.06531     0.27806     0.06334     0.01395     0.00004          1 \n",
      "       168     0.12485     0.04918     0.03253     0.00270     0.00002          0 \n",
      "       169     0.05276     0.03553     0.14849     0.00218     0.00000          2 \n",
      "       170     0.08015     0.06180     0.19207     0.00172     0.00001          2 \n",
      "       171     0.03199     0.12926     0.02112     0.01185     0.00006          1 \n",
      "       172     0.02421     0.01875     0.11396     0.00271     0.00001          2 \n",
      "       173     0.05405     0.05523     0.22020     0.00397     0.00001          2 \n",
      "       174     0.06735     0.04019     0.09745     0.00136     0.00000          2 \n",
      "       175     0.11079     0.08386     0.10670     0.00715     0.00001          0 \n",
      "       176     0.04200     0.01573     0.00750     0.00136     0.00000          0 \n",
      "       177     0.04084     0.19332     0.06320     0.00509     0.00000          1 \n",
      "       178     0.07740     0.11258     0.26483     0.00777     0.00000          2 \n",
      "       179     0.05563     0.10213     0.05365     0.00259     0.00000          1 \n",
      "       180     0.10521     0.13635     0.35143     0.00509     0.00000          2 \n",
      "       181     0.12301     0.03145     0.03947     0.00190     0.00000          0 \n",
      "       182     0.02374     0.01680     0.05380     0.00789     0.00000          2 \n",
      "       183     0.28326     0.10270     0.11586     0.00251     0.00001          0 \n",
      "       184     0.08402     0.13750     0.07135     0.00881     0.00001          1 \n",
      "       185     0.03682     0.09436     0.02808     0.00060     0.00002          1 \n",
      "       186     0.09617     0.13509     0.34139     0.00372     0.00001          2 \n",
      "       187     0.14961     0.04222     0.02997     0.00356     0.00004          0 \n",
      "       188     0.17061     0.01847     0.01102     0.00779     0.00001          0 \n",
      "       189     0.23565     0.04968     0.07667     0.00254     0.00001          0 \n",
      "       190     0.03321     0.18567     0.06841     0.00271     0.00000          1 \n",
      "       191     0.17216     0.07816     0.07638     0.00344     0.00001          0 \n",
      "       192     0.26228     0.05872     0.07003     0.00248     0.00002          0 \n",
      "       193     0.02420     0.10548     0.03789     0.00860     0.00001          1 \n",
      "       194     0.03957     0.05737     0.13970     0.00206     0.00000          2 \n",
      "       195     0.15445     0.06116     0.05625     0.00394     0.00004          0 \n",
      "       196     0.08400     0.04794     0.03726     0.00059     0.00000          0 \n",
      "       197     0.03271     0.18907     0.07965     0.00323     0.00000          1 \n",
      "       198     0.05838     0.11302     0.04802     0.01092     0.00000          1 \n",
      "       199     0.02618     0.10271     0.04593     0.00773     0.00001          1 \n",
      "       200     0.04432     0.17724     0.04817     0.00118     0.00001          1 \n",
      "       201     0.03568     0.20018     0.03899     0.00345     0.00000          1 \n",
      "       202     0.04799     0.22372     0.06132     0.00264     0.00000          1 \n",
      "       203     0.01810     0.05982     0.01382     0.00187     0.00012          1 \n",
      "       204     0.12251     0.05949     0.04291     0.00204     0.00001          0 \n",
      "       205     0.13427     0.02683     0.04439     0.00328     0.00002          0 \n",
      "       206     0.04922     0.15775     0.06887     0.00689     0.00000          1 \n",
      "       207     0.25894     0.05688     0.07352     0.00356     0.00001          0 \n",
      "       208     0.05650     0.03897     0.08198     0.00579     0.00000          2 \n",
      "       209     0.15219     0.04314     0.04155     0.00358     0.00001          0 \n",
      "       210     0.10915     0.10931     0.39978     0.00352     0.00001          2 \n",
      "       211     0.12351     0.03450     0.04082     0.00329     0.00001          0 \n",
      "       212     0.08727     0.06901     0.06217     0.00304     0.00001          0 \n",
      "       213     0.02521     0.04602     0.06428     0.01119     0.00000          2 \n",
      "       214     0.16236     0.05304     0.05688     0.00136     0.00002          0 \n",
      "       215     0.00085     0.00139     0.00020     0.02968     0.99996          4 \n",
      "       216     0.22971     0.06042     0.07553     0.00157     0.00000          0 \n",
      "       217     0.15477     0.10596     0.27673     0.00409     0.00001          2 \n",
      "       218     0.06905     0.26680     0.07203     0.00397     0.00001          1 \n",
      "       219     0.04813     0.06457     0.16270     0.00095     0.00000          2 \n",
      "       220     0.26310     0.06937     0.09128     0.00290     0.00311          0 \n",
      "       221     0.05242     0.05514     0.20674     0.00358     0.00000          2 \n",
      "       222     0.03186     0.17702     0.03591     0.00321     0.00014          1 \n",
      "       223     0.14154     0.09223     0.19561     0.00248     0.00001          2 \n",
      "       224     0.04103     0.05914     0.13665     0.01123     0.00002          2 \n",
      "       225     0.14007     0.04620     0.03959     0.00562     0.00002          0 \n",
      "       226     0.18361     0.04959     0.05363     0.00131     0.00001          0 \n",
      "       227     0.21729     0.06962     0.07434     0.00553     0.00002          0 \n",
      "       228     0.06716     0.14115     0.07026     0.00375     0.00000          1 \n",
      "       229     0.12769     0.03444     0.03507     0.00580     0.00003          0 \n",
      "       230     0.08650     0.15285     0.13677     0.00725     0.00001          1 \n",
      "       231     0.06312     0.15721     0.08165     0.00408     0.00003          1 \n",
      "       232     0.05718     0.19555     0.14435     0.00676     0.00001          1 \n",
      "       233     0.07581     0.08951     0.04819     0.00309     0.00000          1 \n",
      "       234     0.05631     0.04081     0.12580     0.00411     0.00000          2 \n",
      "       235     0.17954     0.09606     0.11932     0.00502     0.00001          0 \n",
      "       236     0.10787     0.31085     0.13353     0.01201     0.00001          1 \n",
      "       237     0.13768     0.03656     0.03561     0.00126     0.00003          0 \n",
      "       238     0.17351     0.06467     0.05608     0.01364     0.00003          0 \n",
      "       239     0.04683     0.14599     0.04461     0.00343     0.00000          1 \n",
      "       240     0.13306     0.06804     0.04919     0.00257     0.00003          0 \n",
      "       241     0.06826     0.18513     0.07470     0.00138     0.00000          1 \n",
      "       242     0.04244     0.01456     0.02355     0.00018     0.00000          0 \n",
      "       243     0.02890     0.14594     0.04573     0.02088     0.00177          1 \n",
      "       244     0.03116     0.08471     0.03560     0.00612     0.00001          1 \n",
      "       245     0.23161     0.07944     0.06990     0.00433     0.00002          0 \n",
      "       246     0.09643     0.12857     0.03796     0.01106     0.00010          1 \n",
      "       247     0.10919     0.04793     0.05385     0.00231     0.00001          0 \n",
      "       248     0.04777     0.07002     0.03209     0.00278     0.00002          1 \n",
      "       249     0.08163     0.11239     0.07210     0.00217     0.00002          1 \n",
      "       250     0.17629     0.07968     0.09246     0.00437     0.00002          0 \n",
      "       251     0.15004     0.07478     0.06278     0.00460     0.00001          0 \n",
      "       252     0.08844     0.06251     0.05811     0.00479     0.00000          0 \n",
      "       253     0.04737     0.09608     0.19292     0.00425     0.00000          2 \n",
      "       254     0.03947     0.15177     0.04086     0.00778     0.00004          1 \n",
      "       255     0.05388     0.05208     0.13228     0.00241     0.00000          2 \n",
      "       256     0.08496     0.18561     0.06832     0.01352     0.00016          1 \n",
      "       257     0.12446     0.15550     0.51789     0.00549     0.00000          2 \n",
      "       258     0.04079     0.14099     0.06091     0.01067     0.00003          1 \n",
      "       259     0.00085     0.00135     0.00020     0.02888     0.99995          4 \n",
      "       260     0.22044     0.06821     0.08328     0.00291     0.00002          0 \n",
      "       261     0.12673     0.04905     0.04272     0.00402     0.00000          0 \n",
      "       262     0.06437     0.13468     0.07297     0.00463     0.00001          1 \n",
      "       263     0.09934     0.02523     0.02719     0.00446     0.00001          0 \n",
      "       264     0.03402     0.02525     0.03369     0.01472     0.00001          0 \n",
      "       265     0.03826     0.18436     0.04593     0.00434     0.00000          1 \n",
      "       266     0.04876     0.07152     0.02801     0.01185     0.00004          1 \n",
      "       267     0.14108     0.03650     0.03344     0.00357     0.00002          0 \n",
      "       268     0.14551     0.07562     0.07928     0.00261     0.00003          0 \n",
      "       269     0.02018     0.06934     0.04138     0.00218     0.00003          1 \n",
      "       270     0.29100     0.07976     0.09651     0.00566     0.00011          0 \n",
      "       271     0.07303     0.02950     0.02588     0.00573     0.00001          0 \n",
      "       272     0.16614     0.05013     0.04074     0.00610     0.00001          0 \n",
      "       273     0.04423     0.07798     0.04595     0.00181     0.00001          1 \n",
      "       274     0.13378     0.03951     0.03748     0.00361     0.00003          0 \n",
      "       275     0.04984     0.19432     0.05307     0.00520     0.00012          1 \n",
      "       276     0.18893     0.05277     0.06070     0.00511     0.00002          0 \n",
      "       277     0.02037     0.13030     0.02359     0.00086     0.00000          1 \n",
      "       278     0.07118     0.01989     0.03257     0.00230     0.00000          0 \n",
      "       279     0.05010     0.07712     0.04870     0.01184     0.00000          1 \n",
      "       280     0.02760     0.07335     0.03577     0.00573     0.00001          1 \n",
      "       281     0.06266     0.24063     0.09621     0.02203     0.00011          1 \n",
      "       282     0.02417     0.09167     0.04293     0.00479     0.00000          1 \n",
      "       283     0.20266     0.07512     0.07675     0.00307     0.00001          0 \n",
      "       284     0.06477     0.06563     0.05443     0.00129     0.00000          1 \n",
      "       285     0.06426     0.05505     0.13916     0.00223     0.00000          2 \n",
      "       286     0.00642     0.02139     0.01755     0.00093     0.00000          1 \n",
      "       287     0.09163     0.05293     0.10429     0.00279     0.00001          2 \n",
      "       288     0.08665     0.28240     0.10333     0.00581     0.00002          1 \n",
      "       289     0.07134     0.05709     0.03608     0.00993     0.00000          0 \n",
      "       290     0.23512     0.06588     0.08450     0.00304     0.00000          0 \n",
      "       291     0.05265     0.06851     0.05428     0.00250     0.00004          1 \n",
      "       292     0.11712     0.03567     0.04032     0.00781     0.00001          0 \n",
      "       293     0.17412     0.04943     0.06849     0.00180     0.00001          0 \n",
      "       294     0.15661     0.10131     0.08155     0.00261     0.00000          0 \n",
      "       295     0.05153     0.05432     0.02832     0.00923     0.00000          1 \n",
      "       296     0.10558     0.03789     0.05086     0.03251     0.00005          0 \n",
      "       297     0.12738     0.03043     0.03427     0.00301     0.00001          0 \n",
      "       298     0.09647     0.02326     0.02017     0.00563     0.00002          0 \n",
      "       299     0.03063     0.16697     0.04857     0.01065     0.00000          1 \n",
      "       300     0.06731     0.22788     0.06305     0.00821     0.00001          1 \n",
      "       301     0.07133     0.33947     0.12444     0.00963     0.00001          1 \n",
      "       302     0.12948     0.03670     0.04194     0.00775     0.00003          0 \n",
      "       303     0.03172     0.03429     0.06218     0.00056     0.00000          2 \n",
      "       304     0.02132     0.16551     0.02935     0.00377     0.00000          1 \n",
      "       305     0.08332     0.01575     0.02197     0.00150     0.00000          0 \n",
      "       306     0.08992     0.01790     0.02238     0.00185     0.00003          0 \n",
      "       307     0.05034     0.14557     0.07800     0.00454     0.00000          1 \n",
      "       308     0.07298     0.08739     0.03663     0.00601     0.00002          1 \n",
      "       309     0.17406     0.06442     0.06048     0.01072     0.00009          0 \n",
      "       310     0.05105     0.04310     0.09278     0.00103     0.00000          2 \n",
      "       311     0.07941     0.10439     0.13521     0.00330     0.00001          2 \n",
      "       312     0.14093     0.04287     0.04442     0.02352     0.00003          0 \n",
      "       313     0.11444     0.04503     0.04106     0.00225     0.00001          0 \n",
      "       314     0.14974     0.04046     0.04827     0.00177     0.00003          0 \n",
      "       315     0.16336     0.06427     0.05303     0.00998     0.00002          0 \n",
      "       316     0.01640     0.09849     0.02557     0.02032     0.00004          1 \n",
      "       317     0.02906     0.11400     0.02882     0.00262     0.00001          1 \n",
      "       318     0.06105     0.06211     0.05218     0.00185     0.00000          1 \n",
      "       319     0.12033     0.03868     0.03961     0.00341     0.00002          0 \n",
      "       320     0.07995     0.06319     0.18022     0.00156     0.00001          2 \n",
      "       321     0.14001     0.04167     0.04029     0.00130     0.00000          0 \n",
      "       322     0.07859     0.08197     0.26152     0.00445     0.00001          2 \n",
      "       323     0.04707     0.10526     0.12908     0.00399     0.00000          2 \n",
      "       324     0.05647     0.02227     0.02064     0.00360     0.00000          0 \n",
      "       325     0.02270     0.08404     0.03668     0.00447     0.00000          1 \n",
      "       326     0.09319     0.03135     0.09384     0.00201     0.00000          2 \n",
      "       327     0.04981     0.10990     0.02799     0.00776     0.00006          1 \n",
      "       328     0.04854     0.04513     0.13296     0.00479     0.00000          2 \n",
      "       329     0.06937     0.09062     0.34971     0.00411     0.00001          2 \n",
      "       330     0.05841     0.12952     0.18743     0.02355     0.00024          2 \n",
      "       331     0.12784     0.06128     0.05635     0.00227     0.00001          0 \n",
      "       332     0.04183     0.01683     0.00253     0.00006     0.00000          0 \n",
      "       333     0.08671     0.02231     0.02196     0.00224     0.00005          0 \n",
      "       334     0.09458     0.10594     0.20691     0.00461     0.00001          2 \n",
      "       335     0.15069     0.04459     0.05619     0.01158     0.00002          0 \n",
      "       336     0.02060     0.08540     0.03617     0.00247     0.00002          1 \n",
      "       337     0.04181     0.05871     0.03077     0.00378     0.00001          1 \n",
      "       338     0.27220     0.13256     0.14899     0.00558     0.00007          0 \n",
      "       339     0.05306     0.13190     0.04224     0.00183     0.00001          1 \n",
      "       340     0.06573     0.07490     0.18424     0.00573     0.00005          2 \n",
      "       341     0.08952     0.08777     0.04164     0.00341     0.00002          0 \n",
      "       342     0.14990     0.05615     0.06699     0.00129     0.00001          0 \n",
      "       343     0.14930     0.05984     0.04468     0.00164     0.00003          0 \n",
      "       344     0.07546     0.05803     0.10660     0.00901     0.00000          2 \n",
      "       345     0.13191     0.07238     0.07379     0.00161     0.00000          0 \n",
      "       346     0.03825     0.03276     0.16447     0.00027     0.00000          2 \n",
      "       347     0.04687     0.04876     0.04019     0.01110     0.00005          1 \n",
      "       348     0.15787     0.04742     0.04189     0.00552     0.00001          0 \n",
      "       349     0.07005     0.04393     0.04752     0.00078     0.00001          0 \n",
      "       350     0.07417     0.03012     0.02145     0.00192     0.00001          0 \n",
      "       351     0.05559     0.16355     0.05031     0.01171     0.00002          1 \n",
      "       352     0.18950     0.05316     0.07584     0.00366     0.00000          0 \n",
      "       353     0.07688     0.04889     0.04696     0.00454     0.00000          0 \n",
      "       354     0.07067     0.24707     0.09016     0.01159     0.00002          1 \n",
      "       355     0.13928     0.07645     0.07649     0.00589     0.00002          0 \n",
      "       356     0.17530     0.06157     0.07400     0.00221     0.00000          0 \n",
      "       357     0.03044     0.03027     0.02634     0.00109     0.00000          0 \n",
      "       358     0.04560     0.02714     0.02530     0.00650     0.00001          0 \n",
      "       359     0.04093     0.09971     0.04499     0.00269     0.00001          1 \n",
      "       360     0.13625     0.07225     0.10697     0.00315     0.00002          0 \n",
      "       361     0.10097     0.03410     0.02854     0.00724     0.00003          0 \n",
      "       362     0.37206     0.10130     0.13191     0.00326     0.00001          0 \n",
      "       363     0.07316     0.08778     0.24393     0.00287     0.00000          2 \n",
      "       364     0.11399     0.05243     0.05209     0.00327     0.00002          0 \n",
      "       365     0.07150     0.23190     0.08894     0.00704     0.00001          1 \n",
      "       366     0.08765     0.06008     0.04771     0.00091     0.00000          0 \n",
      "       367     0.07968     0.02877     0.03090     0.00199     0.00001          0 \n",
      "       368     0.07855     0.07759     0.26180     0.00408     0.00001          2 \n",
      "       369     0.07018     0.06142     0.09081     0.00368     0.00000          2 \n",
      "       370     0.04226     0.13352     0.03503     0.00264     0.00001          1 \n",
      "       371     0.05678     0.11661     0.06746     0.00506     0.00001          1 \n",
      "       372     0.09348     0.14096     0.12159     0.00364     0.00001          1 \n",
      "       373     0.09396     0.03248     0.04957     0.00060     0.00000          0 \n",
      "       374     0.02845     0.11325     0.04878     0.00674     0.00000          1 \n",
      "       375     0.20252     0.05799     0.08906     0.00144     0.00001          0 \n",
      "       376     0.18727     0.11279     0.09969     0.00999     0.00001          0 \n",
      "       377     0.09068     0.03452     0.03259     0.00084     0.00000          0 \n",
      "       378     0.11408     0.03732     0.03639     0.00226     0.00001          0 \n",
      "       379     0.19057     0.07215     0.06701     0.01289     0.00007          0 \n",
      "       380     0.21010     0.06285     0.05704     0.00429     0.00001          0 \n",
      "       381     0.21223     0.05942     0.07993     0.00137     0.00001          0 \n",
      "       382     0.06233     0.17160     0.07390     0.00575     0.00001          1 \n",
      "       383     0.19894     0.04629     0.05757     0.00138     0.00000          0 \n",
      "       384     0.09969     0.15392     0.10322     0.01205     0.00003          1 \n",
      "       385     0.11682     0.04162     0.03935     0.00373     0.00002          0 \n",
      "       386     0.05335     0.13081     0.06882     0.02250     0.00000          1 \n",
      "       387     0.04332     0.22280     0.05689     0.01217     0.00000          1 \n",
      "       388     0.19609     0.06246     0.07646     0.00250     0.00001          0 \n",
      "       389     0.04495     0.05240     0.05365     0.00116     0.00000          2 \n",
      "       390     0.06720     0.12925     0.04480     0.00385     0.00006          1 \n",
      "       391     0.03172     0.07569     0.04355     0.00398     0.00017          1 \n",
      "       392     0.05551     0.02897     0.02044     0.00726     0.00004          0 \n",
      "       393     0.03289     0.16955     0.05303     0.00431     0.00004          1 \n",
      "       394     0.06681     0.05925     0.04419     0.00059     0.00001          0 \n",
      "       395     0.04662     0.24330     0.07706     0.01020     0.00003          1 \n",
      "       396     0.07314     0.08443     0.34234     0.00351     0.00000          2 \n",
      "       397     0.20620     0.05419     0.06674     0.00261     0.00001          0 \n",
      "       398     0.00576     0.07419     0.00719     0.00000     0.00000          1 \n",
      "       399     0.11638     0.03297     0.02087     0.00224     0.00004          0 \n",
      "       400     0.07216     0.06239     0.22636     0.00558     0.00004          2 \n",
      "       401     0.14712     0.04490     0.04487     0.02155     0.00002          0 \n",
      "       402     0.08205     0.20498     0.07684     0.00455     0.00002          1 \n",
      "       403     0.08886     0.06257     0.16387     0.00186     0.00000          2 \n",
      "       404     0.01702     0.09798     0.02961     0.00153     0.00001          1 \n",
      "       405     0.05858     0.06840     0.04767     0.00061     0.00000          1 \n",
      "       406     0.02920     0.08189     0.07134     0.00437     0.00000          1 \n",
      "       407     0.10198     0.05264     0.04573     0.00456     0.00000          0 \n",
      "       408     0.04669     0.10182     0.04950     0.00107     0.00002          1 \n",
      "       409     0.09459     0.11826     0.34954     0.00296     0.00000          2 \n",
      "       410     0.10767     0.05348     0.04928     0.01347     0.00002          0 \n",
      "       411     0.06821     0.08910     0.18334     0.00334     0.00000          2 \n",
      "       412     0.20819     0.06514     0.08451     0.00547     0.00001          0 \n",
      "       413     0.23610     0.05396     0.05990     0.00244     0.00001          0 \n",
      "       414     0.03541     0.10259     0.04922     0.01173     0.00000          1 \n",
      "       415     0.28230     0.10005     0.10374     0.00253     0.00002          0 \n",
      "       416     0.07239     0.20702     0.07360     0.00847     0.00003          1 \n",
      "       417     0.14441     0.10247     0.23893     0.00315     0.00000          2 \n",
      "       418     0.17766     0.04895     0.06270     0.00897     0.00000          0 \n",
      "       419     0.02407     0.10108     0.01333     0.23117     0.00013          3 \n",
      "       420     0.07907     0.10077     0.25289     0.00940     0.00001          2 \n",
      "       421     0.03649     0.02969     0.14461     0.00096     0.00000          2 \n",
      "       422     0.04522     0.07861     0.08324     0.00586     0.00002          2 \n",
      "       423     0.08733     0.06337     0.05651     0.00205     0.00000          0 \n",
      "       424     0.03975     0.06814     0.03093     0.00098     0.00000          1 \n",
      "       425     0.07359     0.22134     0.09619     0.00501     0.00000          1 \n",
      "       426     0.18484     0.06131     0.05845     0.00659     0.00001          0 \n",
      "       427     0.09073     0.33409     0.11564     0.00958     0.00001          1 \n",
      "       428     0.13375     0.02532     0.01657     0.01946     0.00001          0 \n",
      "       429     0.07033     0.17144     0.08995     0.00801     0.00002          1 \n",
      "       430     0.03076     0.17633     0.05178     0.00960     0.00001          1 \n",
      "       431     0.07997     0.10664     0.06921     0.01271     0.00004          1 \n",
      "       432     0.06819     0.02890     0.02287     0.00362     0.00007          0 \n",
      "       433     0.02216     0.06695     0.03608     0.00089     0.00000          1 \n",
      "       434     0.02170     0.02123     0.02614     0.00221     0.00001          2 \n",
      "       435     0.06744     0.03617     0.05735     0.00238     0.00001          0 \n",
      "       436     0.03162     0.05962     0.01911     0.00278     0.00000          1 \n",
      "       437     0.07831     0.08469     0.04141     0.00192     0.00001          1 \n",
      "       438     0.03971     0.04441     0.15532     0.00072     0.00000          2 \n",
      "       439     0.03305     0.03642     0.15785     0.02217     0.00001          2 \n",
      "       440     0.09253     0.07682     0.20861     0.00556     0.00001          2 \n",
      "       441     0.07577     0.12970     0.12711     0.00730     0.00001          1 \n",
      "       442     0.04772     0.05210     0.04797     0.00263     0.00001          1 \n",
      "       443     0.03447     0.08346     0.02936     0.00574     0.00002          1 \n",
      "       444     0.06911     0.06991     0.05162     0.01125     0.00002          1 \n",
      "       445     0.26637     0.07307     0.07861     0.00139     0.00001          0 \n",
      "       446     0.24207     0.08141     0.10101     0.00172     0.00001          0 \n",
      "       447     0.00165     0.02256     0.00629     0.00065     0.00000          1 \n",
      "       448     0.02472     0.01419     0.02776     0.00395     0.00001          2 \n",
      "       449     0.07349     0.12214     0.05299     0.00595     0.00805          1 \n",
      "       450     0.12452     0.04238     0.03441     0.00271     0.00001          0 \n",
      "       451     0.05813     0.14302     0.06000     0.00522     0.00002          1 \n",
      "       452     0.05054     0.10195     0.03228     0.01817     0.00003          1 \n",
      "       453     0.14737     0.09101     0.08934     0.00572     0.00001          0 \n",
      "       454     0.25961     0.05098     0.07788     0.00069     0.00000          0 \n",
      "       455     0.07800     0.04971     0.03870     0.00463     0.00000          0 \n",
      "       456     0.05954     0.05433     0.10289     0.00158     0.00000          2 \n",
      "       457     0.09338     0.03547     0.03132     0.01360     0.00001          0 \n",
      "       458     0.14959     0.05954     0.04579     0.00404     0.00002          0 \n",
      "       459     0.03358     0.05571     0.13524     0.01316     0.00002          2 \n",
      "       460     0.09214     0.28508     0.14876     0.01000     0.00001          1 \n",
      "       461     0.07335     0.04430     0.07774     0.00177     0.00000          2 \n",
      "       462     0.10675     0.14086     0.50131     0.00461     0.00000          2 \n",
      "       463     0.04114     0.01656     0.00805     0.00027     0.00000          0 \n",
      "       464     0.04493     0.14922     0.04671     0.00397     0.00002          1 \n",
      "       465     0.03040     0.10137     0.03215     0.00076     0.00000          1 \n",
      "       466     0.06488     0.05511     0.23278     0.00419     0.00001          2 \n",
      "       467     0.04346     0.04043     0.03758     0.00039     0.00000          0 \n",
      "       468     0.02235     0.03358     0.17167     0.00109     0.00000          2 \n",
      "       469     0.14912     0.04971     0.03611     0.00562     0.00001          0 \n",
      "       470     0.05911     0.16852     0.08379     0.00531     0.00001          1 \n",
      "       471     0.06758     0.12254     0.06859     0.00078     0.00000          1 \n",
      "       472     0.14281     0.04324     0.03187     0.00254     0.00001          0 \n",
      "       473     0.10058     0.02747     0.04987     0.00144     0.00000          0 \n",
      "       474     0.06316     0.05189     0.11682     0.00716     0.00002          2 \n",
      "       475     0.08847     0.20729     0.12480     0.02265     0.00006          1 \n",
      "       476     0.19330     0.04902     0.06979     0.00477     0.00001          0 \n",
      "       477     0.06090     0.09824     0.04770     0.00150     0.00000          1 \n",
      "       478     0.01785     0.11620     0.02150     0.00120     0.00001          1 \n",
      "       479     0.10943     0.01591     0.01829     0.01212     0.00000          0 \n",
      "       480     0.05346     0.05737     0.04381     0.00368     0.00000          1 \n",
      "       481     0.02902     0.07387     0.02913     0.00012     0.00000          1 \n",
      "       482     0.01907     0.05042     0.02847     0.00066     0.00001          1 \n",
      "       483     0.16281     0.06844     0.07580     0.00378     0.00003          0 \n",
      "       484     0.09194     0.04652     0.11048     0.00550     0.00000          2 \n",
      "       485     0.05325     0.20233     0.07468     0.00923     0.00000          1 \n",
      "       486     0.14214     0.08115     0.06331     0.00175     0.00003          0 \n",
      "       487     0.10432     0.03614     0.03959     0.00207     0.00001          0 \n",
      "       488     0.13065     0.02829     0.04175     0.00075     0.00000          0 \n",
      "       489     0.08196     0.26469     0.10437     0.01177     0.00001          1 \n",
      "       490     0.14042     0.10871     0.10238     0.00600     0.00002          0 \n",
      "       491     0.04706     0.21443     0.06226     0.00339     0.00001          1 \n",
      "       492     0.01069     0.09893     0.00960     0.00038     0.00000          1 \n",
      "       493     0.03651     0.08024     0.01519     0.00628     0.00009          1 \n",
      "       494     0.09336     0.16203     0.10710     0.00619     0.00002          1 \n",
      "       495     0.05031     0.05322     0.04904     0.00436     0.00001          1 \n",
      "       496     0.12160     0.04768     0.04436     0.00123     0.00001          0 \n",
      "       497     0.16176     0.06376     0.04565     0.00948     0.00004          0 \n",
      "       498     0.15871     0.05836     0.08029     0.00581     0.00001          0 \n",
      "       499     0.07082     0.12889     0.07603     0.00185     0.00001          1 \n"
     ]
    }
   ],
   "source": [
    "results= predict_Cluster(dtTFxIDF_test, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
